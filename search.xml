<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F18%2Flife%2F%E6%91%84%E5%BD%B1%2F</url>
    <content type="text"><![CDATA[摄影曝光模式 A(AV)档 由拍摄者首先选择拍摄所需要的光圈，然后由相机根据现场光线情况确定所需的快门速度。 光圈越大，背景虚化的效果越明显，被拍摄的主体越突出。光圈越小，焦点前后的的景深越大，即前景和背景越清晰。 进行微距拍摄，常常运用较大光圈来达到虚化杂乱背景的目的和效果。 风景拍摄时为了取得前后清晰，细节丰富的图象，常常采用较小的光圈进行拍摄。 S(TV)档 由拍摄者首先选择拍摄所需要的快门速度，然后由相机根据现场光线情况确定所需的光圈。 高速快门可以用于凝固物体瞬间的状态，而慢速快门可以实现运动物体的虚化。 当快门速度低于1/60秒时建议使用三脚架进行拍摄，以免手振影响图象的清晰度。 夜景拍摄常常运用长时间曝光（快门速度较慢，常常达到1-30秒）。 P(AUTO)档 由相机根据现场光线情况自动设定所需的光圈和快门速度。 M档 完全由用户确定拍摄时所需要的光圈和快门速度。 曝光模式 你控制 相机控制 适用情形 P/Auto/各种情景模式 - 光圈、快门、感光度 各种普通场景 A(Av) 光圈 快门、感光度 需要精确控制景深，如人像、静物、微距等场合 S(Tv) 快门 光圈、感光度 需要精确控制曝光时间，如拍摄快速运动或水流等场合 M 光圈、快门 感光度 光照复杂或比较极端，机器无法自动胜任的场合，如星空等弱光环境 Tips：表中情况适用于你的感光度设定为自动的情况。 光圈、快门速度和感光度影响曝光的参数只有三个：光圈、快门速度和感光度。这三个参数相互之间是独立的。 光圈光圈指的是光线透过相机镜头进入感光元件所实现的透光量，通过调整镜头内感光面光量的装置来加以控制。 光圈值用F表示，它是镜头焦距和镜头光圈直径的比，由于比值是倒数的关系，所以就有了这样的对应关系：光圈值越小，光圈孔径越大，进光量也就大，那么获得的景深也就越浅，此时背景虚化效果就比较明显，画面也比较明亮。反之，光圈的孔径越小，进光量减小，景深也就越深，背景与主题就会越清晰，画面也会比较暗。 大光圈可以制造虚化，小光圈容易产生星芒。 一般镜头参数上标注的光圈就是镜头的最大光圈，比如24-70 mm/2.8，表示镜头焦距变化范围24-70毫米，最大光圈是2.8。 Tips：行家们常说的“光圈增加一倍”，意味着通光孔的面积增加，反映到光圈的数值上就是根号二倍，所以f/2.8的光圈提高一倍是f/2，而不是f/1.4。 快门速度许多人在拍摄动态物体时都会遇到拍出来的画面是虚的的情况，这种模糊、没有对焦上的画面往往是因为快门的速度还不够快。 拍摄同一个运动物体，不同的快门速度会产生不同的效果。选择较快的快门速度，以快制快，可以把运动速度较快的物体定格在一瞬间，但是高速快门或多或少会影响进光量，物体虽然定格住了，但是画面可能会偏暗，所以需要人为找一个相对光亮充足的环境下拍摄，必要时可以使用闪光灯辅助拍摄。 一般情况下，有一个防止手抖影响的快门速度，被称之为安全快门值。速度为“1/镜头焦距（秒）”。比如使用焦距为85mm的镜头时，把被摄对象拍摄清楚的快门速度就应该不低于1/85秒。除了全画幅相机，对于APS-C画幅相机，安全快门的计算就需要进行一个简单的换算，用实际焦距乘以相应的转换系数，换算成等效焦距后使用。使用安全快门也并不是一个绝对的快门数值，只是相对会大大提高拍摄的成功率。 拍摄的多了就会慢慢发现一些规律，一般情况下拍摄流水或者瀑布，可以选择1/30秒的快门速度，就可以实现丝绢般的水流效果。拍摄奔跑的儿童或者是移动的动物的时候，可以选择1/30—1/250秒的中等快门速度来拍摄。而水滴这类高速运动的物体，就要用较快的快门速度来实现了，例如1/500—1/1000秒。 感光度（ISO）ISO 代表感光材料对光线的敏感程度，ISO越高，感光元件对光线越敏感，达到同样效果需要的光线量越少；ISO越低，感光元件对光线越迟钝，达到同样效果需要的光线量越多。 简单说，感光度每增加一倍比如ISO 200比ISO 100 表示照片亮度提高了一倍。但高感光度会使照片更粗糙，噪点也会更多。 定焦镜头和变焦镜头定焦镜头（prime lens）特指只有一个固定焦距的镜头，只有一个焦段，或者说只有一个视野。定焦镜头没有变焦功能。 定焦镜头的设计相对变焦镜头而言要简单得多，但一般变焦镜头在变焦过程中对成像会有所影响，而定焦镜头相对于变焦机器的最大好处就是对焦速度快，成像质量稳定。 不少拥有定焦镜头的数码相机所拍摄的运动物体图像清晰而稳定，对焦非常准确，画面细腻，颗粒感非常轻微，测光也比较准确。 定焦镜头适合拍什么？ 定焦镜头的设计简单，对焦速度快，成像质量稳定。特别适合大型的风光摄影，大型的集体合影拍照。 优点 定焦镜头的好处，主要体现在短焦段的使用上： 定焦的广角或标准镜头一般都比涵盖相应焦距段的变焦镜头口径大。一般的定焦广角和中焦镜头的光圈都在2.8以上，通光量大，便于在低照度情况下拍摄。 定焦的广角镜头一般都比涵盖相应焦距段的变焦镜头最短对焦距离近。 广角定焦镜头一般都比变焦镜头的广角段成像好 缺点 定焦镜头唯一的缺点恐怕就是不方便了，需要调整拍摄物体的大小时只有通过摄影者的移动来实现，在某些不适合移动的场合就无能力了。 变焦镜头（定焦35.50.85）（变焦24-70.70-200） 常识焦距镜头的焦距 (focal length)，从实用的角度可以理解为：镜头中心至胶片平面的距离。理论上的定义为：无限远的景物通过透镜或透镜组在焦平面结成清晰影像时，透镜或透镜组的光学中心至焦平面的垂直距离。对于定焦镜头来说，其光学中心的位置是固定不变的；对于变焦镜头来说，镜头的光学中心的变化带来镜头焦距的变化。 一般而言，35mm 相机的标准镜头焦长约是 28-70mm，因此如果焦长高于 70mm 就代表支持望远效果，若是低于 28mm 就表示有广角拍摄能力。 CMOS应用于制作数码影像器材的感光元件，通过将光转化为电子（或电荷）再处理成电子信号的原理来进行影像数据的保存。 在实际使用中，CMOS越大，同条件下所接收的光越多，通常画质与观感就越好、噪点越少等，这也是CMOS越大越贵的原因。 画幅 全画幅（FullFrame） 由胶片时代的传统35毫米胶片尺寸演化而来，CMOS大小与135胶卷尺寸（36×24mm，各个厂商具体尺寸会有微小的差别）相同。 APS-C画幅（Advenced Photo System） APS-C画幅采用的感光器尺寸为25×17mm左右（长宽比为3:2），其面积大约为全画幅的一半，所以也称半画幅。 所谓全画幅也不过是基本对应胶片时代35mm规格胶片的尺寸，现在比全画幅尺寸更大的感光器还有大画幅和中画幅，也有科研领域特制的更大尺寸。 感光器的面积从大到小的顺序依次是：大画幅、中画幅、全画幅、M43、卡片机、手机。 单反相机和微单普遍采用的全画幅和APS-C画幅拍摄出来的照片到底有多大的区别呢？ 全画幅感光器面积更大，可以承载更多的物理像素，更多的像素在定义分辨率后输出的图片尺寸就更大。相对APS-C画幅来说，其面积大了约一倍，如果不是按比例增加（如APS-C2400万像素，全画幅增加到4800万像素），那么单位面积上的像素密度就会降低，像素密度在更优选的范围，这样可以减少像素之间的干扰，拍摄出来的照片就会有更优的画质，如更好宽容度等。但如果像素按比例增加，这个优势就不明显了，因为像素密度相等了。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F10%2Flife%2Fclassical-music%2F%E5%85%A5%E9%97%A8%E4%B8%89%E5%8D%83%E9%97%AE%2F</url>
    <content type="text"><![CDATA[小白入门三千问 为什么交响乐队里第一小提琴首席是指挥之外的第二号人物？https://www.zhihu.com/question/20948213]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F10%2Flife%2Fclassical-music%2F%E5%8B%83%E6%8B%89%E5%A7%86%E6%96%AF%2F</url>
    <content type="text"><![CDATA[勃拉姆斯总结勃拉姆斯是公认的非常严肃的作曲家，但他也写过一些相对通俗轻松的作品。比如，由 21 首舞曲组成的一套《匈牙利舞曲》，可能就是勃拉姆斯最通俗，最广为人知的作品。 代表作21 首舞曲组成的《匈牙利舞曲》这套舞曲中每一首乐曲的旋律和风格不尽相同，却都混合着浓郁的民族热色：节奏自由，旋律富有装饰性，速度变化激烈，带有一定的即兴性。 所谓风从民间来，这 21 首舞曲虽然被冠以“匈牙利舞曲”之名，但据后人研究，大部分乐曲的风格或原始曲调，实际是出自在匈牙利的吉普赛人的音乐。 据研究，这 21 首舞曲中，只有第 11，第 14 和第 16 首，完全是勃拉姆斯的原创。而他最初的版本，是为钢琴而作的四手联弹。后来他还曾将前 10 首，改编成钢琴独奏。 不过，当代人们经常听到的，是管弦乐队的版本。这其中第 1、2、5、9、14 等都是非常有名的作品。 《升 f 小调匈牙利舞曲第五号》曾在卓别林的喜剧电影《大独裁者》中作为插曲出现，理发师按此音乐的节奏，为顾客刮胡子的片断，成为电影史上的经典片段。 《 g 小调匈牙利舞曲第一号》充满了难言的优美，缠绵得动人心魄。 知识点]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F10%2Flife%2Fclassical-music%2F%E5%9C%A3%E6%A1%91%2F</url>
    <content type="text"><![CDATA[圣桑总结圣桑（Saint-Saens，1835 - 1921）是法国浪漫主义时期的作曲家，被后世称为“法国的门德尔松”。 19 世纪的法国音乐界，正被一批守旧平庸之辈把持，音乐创作和演奏中都弥漫着奢华浮夸之风。而圣桑音乐曲风巧妙而优雅，却与所处的时代分道扬镳。 代表作管弦乐组曲《动物狂欢节》在 14 首组曲中，圣桑分别借用每种动物的寓意，向现实发出批判。比如，第 1 首《狮子》，其实是讽刺社会上那些养尊处优的平庸之辈；接下来的《公鸡与母鸡》，则是为了鞭挞那些自命不凡的君子。 天鹅这首《天鹅》充满了温柔的力量。圣桑打破了其他乐章中惯用的嘲弄和讽刺，开始歌颂天鹅身上所寄托的纯洁和善良，保留了人们对天鹅所有的美学评价。 这首曲子的画面带入感很强。乐曲一开场，在钢琴梦幻般的呓语伴奏之下，深沉的大提琴声响起，带着几丝淡淡的忧伤。之后，一只洁白的天鹅悄然出现。她身负重伤，可仍旧挺着优雅的长颈，将高贵的头颅伸向月夜穹苍。 这首曲子太美，所以时常被改编成各种乐器的独奏曲，或是配合舞蹈的形式来演绎。最后，给大家推荐的这段小型芭蕾作品《天鹅之死》，就是各类衍生创作中的成功代表，高冷而凄美。 而这段芭蕾的表演者安娜·巴甫洛娃，一生表演这个片段超过 4000 次，同样成为后世的经典。芭蕾舞 天鹅之死 知识点]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F10%2Flife%2Fclassical-music%2F%E9%9F%B3%E4%B9%90%E5%8F%B2%2F</url>
    <content type="text"><![CDATA[浪漫主义时期乐派 魏玛乐派奉行当时极为盛行的浪漫主义标题音乐，代表人物李斯特、瓦格纳、柏辽兹等。 莱比锡乐派倡导无标题音乐，代表人物勃拉姆斯、等。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F10%2Flife%2Fclassical-music%2F%E5%B7%B4%E8%B5%AB%2F</url>
    <content type="text"><![CDATA[[toc] 巴赫总结巴赫的音乐是纯音乐，即根据音乐的逻辑来创作，而非根据文学等。 巴赫的音乐适合当作建筑来听，了解内部的细节和逻辑，可以有深入了解；早年间只是音乐家喜欢的音乐家，直到1829年，其逝世百年后，被门德尔松发现、演奏马太受难曲，而被世人发现。 代表作平均律钢琴曲集(四十八首前奏曲与赋格)巴赫的《平均律钢琴曲集》包括四十八首赋格，从二部到五部，其中第10首，即e小调赋格曲，是唯一的二部赋格。 无伴奏大提琴组曲共有6套36首曲目，包括六种风格各异的舞曲：序奏、阿勒曼德舞曲、库朗舞曲、萨拉邦德舞曲、小步舞曲、吉格舞曲。这些都是当时欧洲流行的舞曲样式。它被誉为是大提琴界的圣经。百度百科 无伴奏大提琴组曲 哥德堡变奏曲最有名的作品。加拿大怪才古尔德弹奏最佳，出道第一张、生前最后一张录制CD，颗粒分明且饱满。 勃兰登堡协奏曲巴赫最著名的协奏曲（大协奏曲），共有6首，每首的乐器组合各不相同。第2首和第5首最佳。例如第2首由小提琴、单簧管、高音小号、长笛四位乐手演奏的四重协奏曲。第4首由小提琴和两个长笛组成的三重协奏曲。互动百科 勃兰登堡协奏曲 事迹/勃兰登堡协奏曲1719—1721年，应勃兰登堡侯爵之约，巴赫创作了一套六首题为“为几件乐器而写的协奏曲”曲集，这套曲集后来被称为《勃兰登堡协奏曲》。 这六首大协奏曲是巴赫同类作品中最伟大的杰作，也是他自由发挥其技能的最佳范例之一，被后人称为是所有合奏协奏曲中最优秀的作品和巴罗克协奏曲的典范。这个时期正是巴赫创作的顶峰，作品丰富而优秀。在这组作品中，巴赫以鬼斧神工的熟练技巧展开动机，而除了创造纯粹的欢愉之外，并无其它任何意图。巴赫动员了当时所有可能的乐器编制，同时更借助了巧妙的乐思应用。 六首协奏曲的风格迥异，不仅乐器组合彼此不同，而且协奏方式也各异。第一、三、六首中没有独奏乐器组显现，协奏关系表现在乐队分与合的布局之中，接近室内交响乐的风格。第二首是长笛、双簧管、小提琴和高音小号的四重协奏曲，高音小号和第一协奏曲中高音小提琴的音色，在现代的乐队中是很难听到的。第四首是小提琴和两支长笛的三重协奏曲。第五首是羽管键琴、小提琴和长笛的三重协奏曲。值得注意的是，该首协奏曲在第一乐章结束前的那一大段的羽管键琴独奏，或许正是现代协奏曲中华彩乐段的鼻祖。 这六首协奏曲的第一乐章都是以活泼明快的气氛开始。这是一种典型的社交音乐，体面、欢乐、有点趾高气扬，是当时这类音乐的标签，适用于任何仪式、庆典、宴会等场面。整个乐章只建立在一个单一的主题之上。巴赫在创作上坚持着每次只做一件事的古老原则，在一个音乐内核中尽情挥洒自己的才能。这或许会被认为是一种单调的音乐，因为它不象现代的协奏曲，对比的主题形象，产生二元的戏剧效果，戏剧效果产生故事。我们已经习惯了听故事，一旦没有听到所期望的戏剧效果，便会感觉音乐平淡。其实，我们应该学会每次寻听一种情感，多数的人生不也是在平淡中走过的吗？ 第二乐章都是抒情的慢板乐章。这里即有沉思、忧伤情绪又有充满诗意田园画卷。聆听这一乐章，不求在音乐中得到什么，只需放松身心，享受缓缓流过的音乐时光。 传统的热情又回到第三乐章。巴赫在这里向我们展示了他高超的作曲技巧。 第二、四、五首以赋格体结束。巴赫将这种对位音乐的最高形式发展到了顶峰,后面再也不曾有人超越这位巨人。一个音乐主题飞翔在乐队的各个声部之间,变化多端、穿梭往来。赋格曲就象延绵起伏的山脉、海浪一样,错落有致,乐队中每个声部的个性都能被听到。第一、三、六首采用民间舞曲体裁,热烈欢快的民间舞蹈正适合套曲的结束。 巴赫的音乐犹如美丽的建筑,从细节到整体都和谐完美。欣赏巴赫的音乐,不要期望会给你讲故事,也不要指望他的音乐会带给你过度的感情宣泄或令人震撼的效果。音乐在这里仅仅提供最基本的情绪元素,让你在平静中感觉音乐在心中流过,感觉这一砖一石建起来的音乐殿堂。 《勃兰登堡协奏曲》在巴赫一生浩如烟海的作品目录中并不醒目,但却是管弦乐作品中的典范之作,至今仍是世界各大乐团的保留曲目。 这张录音是非常著名的，卡尔·李希特与他指挥的慕尼黑巴赫乐团堪称巴赫作品的最佳诠释组合之一，也被誉为最富有德国气质的巴赫作品演奏专家。李希特的演绎舒缓平稳，而且非完全仿古，但是在精神层面他却具有与巴赫最为贴近的气质，而且具有令人屏息的戏剧性与魅力，充满对现世的否定和对彼岸的向往。这套唱片虽然是60年代的录音，但是效果却非常出色。 C大调前奏曲其他《马太受难曲》《b小调弥撒》《平均律钢琴曲》《音乐的奉献》《半音阶幻想曲与赋格》《赋格的艺术》 知识点赋格曲 FUGE赋格的主要结构是首先在一个声部上出现一个主题片断，然后在其他的声部上模仿这个片断，这时演奏主题的声部演奏与新的声部相对应的乐句，形成各个声部相互问答追逐的效果。赋格通常没有引子。赋格一般分为三个部分：呈现部，中间部和再现部。各个声部在呈现部中用主调和属调将主题一一呈现一遍，然后各自展开成为不同的插部，最后在再现部里回到原来的主题上。 在赋格开始的地方，第一个声部进入时出现的短的旋律或乐句称为赋格主题，赋格主题不同于奏鸣曲式以及其他曲式的主题，赋格主题是短小的一句旋律，仅仅具有简单的线条,而不是像其他的主题那样可以有完整的和声。 第二个声部通常在高一个五度或者低一个四度的地方进入，即在属调上重复主题，称为答题；同时刚才的第一个声部演奏对位的旋律性伴奏声部，称为对题，对题也可以不出现，而仅有相对简单的伴奏。 第三个声部进入，通常回到主调，即比第一个声部高或低八度，同时第二个声部继续演奏对题，第一个声部则相对自由。主题，对题如此在主调和属调上循环。 百度百科 赋格如何欣赏赋格？ 变奏曲由主题不断变化，反复，并拥有统一构思的乐曲。特点是以主题为主干，进行各种变化，比如加花，变音型，变速度，转调等等。如莫扎特《小星星变奏曲》，一闪一闪亮晶晶……。 变奏曲（Bianzouqu）全称：主题与变奏曲由一个主题与根据这个主题写成的一组变奏曲组成。作曲家可新创主题，也可借用现成曲调。然后保持主题的基本骨架而加以自由发挥。手法有装饰变奏、对应变奏、曲调变奏、音型变奏、卡农变奏、和声变奏、特性变奏等。另外，还可以在拍子、速度、调性等方面加以变化而成一段变奏。变奏少则数段。多则数十段。变奏曲可作为独立的作品，也可作为太型作品的一个乐章。 著名作品巴赫的《哥德堡变奏曲》、贝多芬的《迪阿贝利主题变奏曲》、勃拉姆斯的《海顿主题变奏曲》、布里顿的《布里奇主题变奏曲》、柴可夫斯基的《洛可可主题变奏曲》、帕格尼尼的《摩西主题变奏曲》、柯达伊的《孔雀变奏曲》、埃尔加的《谜语变奏曲》、《威尼斯狂欢节幻想变奏曲》、《那坡里民歌主题幻想曲与变奏曲》、《魔笛主题变奏曲》等 前奏曲前奏曲的起源最早可追溯到15、16世纪，当时是曲琉特琴或管风琴作为一种“开场白”式的即兴演奏而来，常用和弦与走句交织而成，起到引入“正题”的作用。 在巴洛克音乐时代，前奏曲经常作为赋格曲的前奏，巴赫就曾为所有12个大调和12个小调写过前奏曲和赋格曲的组合，总称《十二平均律钢琴曲集》。 到了浪漫主义时期，肖邦写的《24首钢琴前奏曲》就有了自己独立的性质，具有浪漫与幻想的风格。李斯特写过一部《前奏曲》，但并不是真正的前奏曲，而是一首独立的交响诗，取材于一首诗，原意为人的一生就是走向死亡的前奏，可是李斯特的作品却不悲观，充满对人生的赞美和肯定。德彪西也写过独立的前奏曲。肖斯塔科维奇也写过钢琴曲《24首前奏曲》（也是和赋格曲的组合）。 肖邦的前奏曲摆脱了“引子”的桎梏，以独特而崭新的面貌出现，成为音乐会及钢琴教材中的常用曲目。之后，德彪西、拉赫玛尼诺夫、斯克里亚宾、肖斯塔科维奇等不同时期的作曲家又各自奉献了具有独特个性与技巧的前奏曲集，丰富和完善了这一钢琴乐种。较之巴洛克时期的前奏曲相比，此时的前奏曲已由“配角”的地位升为“主角”了。 巴赫&amp;古诺：《圣母颂》法国浪漫时期的著名音乐家古诺有一首广为流传的歌曲的《圣母颂》，其使用的伴奏是巴赫《平均律钢琴曲集》（Well-Tempered Clavier 1）第一首《C大调前奏曲与赋格》（BWV846）的前奏曲部分。《圣母颂》作品始终充满着一种高雅圣洁的氛围，使我们如同 置身于中世纪古朴而肃穆的教堂之中；而《C大调前奏曲与赋格》的前奏曲部分则精美绝伦，集纯洁、宁静、明朗于一身，满怀美好的期盼，以这样一首乐曲作为《圣母颂》的伴奏，确实是恰如其分。最难得的是，古诺竟将它与自己歌曲的旋律结合得天衣无缝，浑然一体，可谓巧夺天工。 咏叹调咏叹调(Aria)既抒情调。这是一种配有伴奏的一个声部或几个声部以优美的旋律表现出演唱者感情的独唱曲。 大协奏曲大协奏曲是独奏协奏曲的先驱。比古典或浪漫时期的协奏曲结构规模较小，大协奏曲的独奏乐器通常都有两件或以上。 附https://www.zhihu.com/question/19603433]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F10%2Flife%2Fclassical-music%2F%E8%82%96%E9%82%A6%2F</url>
    <content type="text"><![CDATA[[toc] 肖邦总结把主要创作精力集中在钢琴上的作曲家，在这狭窄的创作空间里，写了21首夜曲、27首练习曲、24首前奏曲、19首波洛乃兹、4首叙事曲、4首谐谑曲、3首奏鸣曲、4首即兴曲、17首圆舞曲、58首玛祖卡、2首幻想曲和2首协奏曲等，把钢琴音乐的发展提高到前所未有的高度，他被人们誉为浪漫主义的“钢琴诗人”。 代表作波兰舞曲第二十五号B小调马祖卡g小调夜曲g小调第一叙事曲降d大调第十五前奏曲 雨滴知识点叙事曲（ballade）叙事曲一词源出拉丁文ballare，意为跳舞，最初是一种舞蹈歌曲。19世纪中期，波兰作曲家肖邦是首创了钢琴叙事曲这种形式。他的四部叙事曲，旋律优美、感情真挚、内容深刻、气象万千，是钢琴艺术史上的不朽杰作。随后，匈牙利作曲家李斯特、德国作曲家勃拉姆斯和挪威作曲家格里格等人，也都把叙事曲的体裁应用于钢琴作品。 谐谑曲谐谑曲又称诙谐曲，一种乐曲。其主要特点是速度轻快，节奏活跃而明确，常出现突发的强弱对比，带有舞曲性与戏剧性的特征。它常在交响曲等套曲中作为第三乐章出现，以取代宫廷风格的小步舞曲。“谐谑”是指用音乐来表现诙谐，幽默的情趣。谐谑曲沿用了小步舞曲的三拍子节拍和复三段式的结构。 谐谑曲的主要部分是三拍子的，快板，描写扫帚取水、大水泛滥和小巫师急躁的心情。音乐不仅速度很快，而且用了“三小节的节奏”，显得分外活跃。所谓“三小节的节奏”，就是每三小节有一个强拍。 谐谑曲比小步舞曲速度快，节奏活跃，并且常用独特的音调、不常见的节奏型、出其不意的转调和强弱对比、突如其来地反复前面的主题或引进新的主题、突如其来地结束一个段落或结束全曲等手法，造成一种幽默和风趣的效果。 夜曲（nocturne）一种流行于十九世纪的形式自由的三段体器乐短曲，一般中段比较激昂，常有沉思、忧郁的特点。格调高雅，充满浪漫色彩，旋律歌唱性很强，也有叫做交响诗的，是富於诗情的短交响乐。低音部的和弦伴奏配上高音部响出夜的寂静，奏出梦般优雅的旋律，所以叫做夜曲。 最先把夜曲运用到钢琴音乐中的是十九世纪初英国的作曲家约翰·菲尔德，而肖邦把它发展为一种形象丰富、情深意远的钢琴音乐体裁，他的21首夜曲是这一体裁的艺术珍品。 玛祖卡（mazurka）一种三拍子的波兰民间舞曲，情绪热烈，节奏重音常落在第三拍，有的落在第二拍上，这是玛祖卡舞曲最突出的特点。 波洛乃兹（polonaise）又称波兰舞曲，是一种徐缓、庄重具有贵族气质的舞曲。16世纪传入宫廷，后普及到市民阶层，18世纪起成为独立的器乐曲；多用复三部曲式，三拍子，第一拍的后半拍往往有重音，结束在第三拍上。肖邦创作的13首《波洛乃兹》把这种舞曲体裁推向了世界。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F10%2Flife%2Fclassical-music%2F%E8%8E%AB%E6%89%8E%E7%89%B9%2F</url>
    <content type="text"><![CDATA[[toc] 莫扎特总结莫扎特被誉为天才，他的哪些天赋令人难以企及？ 一般来说协奏曲是很难创作好的，原因有二： 一般协奏曲对主角乐器的理解要求很深。简而言之，作曲家也必须是演奏家。也就是说不仅需要了解这一乐器，还要有演奏级技巧才行，这样才能通晓各种演奏技巧，再将其应用在自己的协奏曲里。比如说帕格尼尼是断然写不好钢琴协奏曲的，因为他的钢琴水平不够他写协奏曲。 一般协奏曲需要很精巧的平衡。一个乐队和一件乐器相对衡，两部分谁都不能压倒谁。所以对配器的要求也比交响乐要高得多。简而言之，演奏的还必须是作曲大师才行。典型的失败案例就是我们的肖邦大大。写出的钢琴协奏曲里钢琴部分吊炸天，可乐队部分却让人接连叹气。肖邦自己的原版的几乎不能演奏，后世多亏柏辽兹帮他重新配器才建立了这两首曲子的历史地位。 比如贝多芬，是钢琴大师和小提琴大师，所以他能写出钢协（五首）和小协（一首）来。比如拉赫玛尼诺夫，是钢琴大师，能写出四首钢协。而许多配器大师，比如之前说的柏辽兹，一首协奏曲也写不出。 这其实非常正常。能作为演奏家的作曲家本身已经是少之又少，像老贝这样能双通小提琴和钢琴的已经是凤毛麟角了。 而莫扎特似乎不受此定律限制。。。他写了二十七首钢琴协奏曲。一首三钢琴协奏曲。一首双钢琴协奏曲。两首长笛协奏曲。一首长笛/竖琴协奏曲。五首小提琴协奏曲。一首大提琴协奏曲（丢失）。几首交响协奏曲（小提琴/中提琴，单簧管/双簧管/圆号/巴松管）四首圆号协奏曲。一首巴松管协奏曲。一首双簧管协奏曲。一首单簧管协奏曲。一首小号协奏曲（丢失）。换句话说，他几乎把所有能写的乐器写了个遍。。。 代表作c大调第四十一交响曲 朱庇特歌剧西风颂d小调第十五弦乐四重奏a大调单簧管协奏曲g小调第四十交响曲SHE《不想长大》开头的音乐。 知识点小步舞曲（Minuet）原为法国土风舞，一种三拍子的舞曲。约1650年传入宫廷，逐步变成速度徐缓、风格典雅的舞曲，流行于贵族社会。十七、十八世纪常用于古钢琴组曲和管弦乐套曲中，作为一个乐章（常为第三乐章），也可作为单独的器乐曲。其结构为三段式曲体，中段常用三个声部写成，故称“三声部中段”，沿习至今。 十九世纪初，小步舞曲构成交响曲奏鸣套曲的第三乐章，后又被谐谑曲所代替。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F10%2Flife%2Fclassical-music%2F%E8%B4%9D%E5%A4%9A%E8%8A%AC%2F</url>
    <content type="text"><![CDATA[[toc] 贝多芬总结贝多芬（Ludwig van Beethoven， 1770.12.16-1827.3.26），他是德国作曲家、音乐家，维也纳古典乐派代表人物之一。是“集古典主义之大成，开浪漫主义之先河”的伟大音乐家；他创作的作品对音乐发展有着深远的影响，由此被尊称为乐圣。 贝多芬是世界艺术史上最伟大的作曲家之一，他的创作集中体现了他那巨人般的性格，反映了那个时代的进步思想，他的革命英雄主义形象可以用崇高加以概括。正如他的英雄史诗般的交响曲创作，反映了那个革命时期人们的精神状态。贝多芬的音乐受到了广大人民群众的喜爱与肯定。他的作品既内容丰富，同时又易于为听众所理解和接受。贝多芬的音乐集中体现了他那个时代人民的痛苦和欢乐，斗争和胜利，因此它过去总是那样激励着人们，鼓舞着人们的斗志，直到如今也依旧使人们感到庄严、神圣和鼓舞。 百度百科 路德维希·凡·贝多芬 代表作第五命运交响曲月光奏鸣曲原本不叫月光，是出版商为了更好的销售取的名字。 英雄交响曲原本写给拿破仑，后来拿破仑称帝，愤而改名为《英雄》。 田园交响曲献给爱丽丝原本名字叫《献给》。 知识点]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F10%2Flife%2Fclassical-music%2F%E4%B9%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[木管长笛木管中的花腔女高音。在几百年前，国外的长笛也都是由木质材料制成的，古代长笛音色温暖圆润又比较细腻，但是音量很小，越来越不能适应后来的音乐编制了。现代的长笛多数使用金属材料，不过长笛仍然是主要的木管乐器之一，它是现代管弦乐团中主要的高音旋律乐器之一。 长笛的种类也比较繁多，但交响乐团中使用的长笛一般为C调长笛。一般交响乐队至少用3只长笛，第3长笛兼任短笛，规模大的乐团还可能使用中音长笛。长笛音域宽广，音色优美，演奏技巧灵活，表现力也丰富，与其他乐器协奏起来亲和力强，容易协调，不仅在现代管弦乐和室内乐中担任高音旋律的角色，它也是主要的独奏乐器，和小提琴一样应用广泛。 短笛双簧管双簧管最初形成于17世纪中叶，18世纪时得到广泛使用。双簧管在乐队中常担任主要旋律的演奏， 是出色的独奏乐器，同时也善于合奏和伴奏。此外它还是交响乐队里的调音基准乐器（乐队以双簧管的小字一组的A音定音）。 双簧管音色带有鼻音似的芦片声，善于演奏徐缓如歌的曲调，被誉为“抒情女高音”。柴科夫斯基的《天鹅湖》中的忧郁而优美的白天鹅主题就是由双簧管吹奏的。双簧管难度高，是吉尼斯世界纪录大全中最难的乐器。由于音色甜美，更被称为“公主”。 特别需要注意的是，双簧管（oboe）与单簧管（clarinet）这两种乐器名称的汉译使大多数不了解相关知识的人都难以区分，但实际上它们在吹奏方法、按键系统、音色、外形以及价格等方面均有较大区别，是两种完全不同的木管乐器，不是学会一种就会另一种的（这点在两种乐器的英文上其实也有所体现，充分说明了它们间的区别并不比与长笛（flute）的小），请不要弄混了。 单簧管又称黑管或克拉管，在台湾又称为竖笛（英语称Clarinet，意大利语为Clarinetto，西班牙语为Clarinete，法语为Clarinette，德语为Klarinette），有管弦乐队中的“演说家”和木管乐器中的戏剧女高音之称。高音区嘹亮明朗；中音区富于表情，音色纯净，清澈优美；低音区低沉，浑厚而丰满，是木管乐曲家族中应用最广泛的乐器之一。 单簧管是木管乐器的一种，通常用非洲黑木制造，由木料、硬橡胶或金属制成，有一个鸟嘴形的吹口和圆形的空心，管身由五节可装拆的管体组成，管体成圆筒形，下端为开放的喇叭口。在吹口处固定一个簧片，吹奏者通过簧片和吹口的空间吹气时，并配合下唇适当的压力，薄薄的簧片尖产生振动，使乐器管内的空气柱开始振动，因而发出柔美的音色。 大管巴松，属于木管乐器中的低音乐器，在乐队中经常用于表现一些节奏和诙谐深沉的段落。 萨克斯]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F10%2Flife%2Fclassical-music%2F%E6%9B%B2%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[[toc] 标题音乐和无标题音乐 标题音乐（program music） 用文字、标题来展示情节性乐思（表现文学性内容）或通过模仿、象征、暗示等手段模拟自然音响（表现绘画性内容）的乐曲，产生于18世纪早期浪漫主义音乐。标题音乐一词是由李斯特首创，是音乐与其它姐妹艺术有机结和的产物，音乐与文学、美术等非音乐因素相融合不但提高了音乐艺术的表现力而且对演奏、欣赏等实践环节有积极的作用和影响。 对于标题音乐，人们往往有个误区，就是认为作品只要有标题就是标题音乐。我们熟悉的器乐作品像海顿的交响曲《时钟》、《惊愕》，贝多芬的钢琴奏鸣曲《月光》、《热情》等作品虽有标题但却不是标题音乐，这些作品的标题是出版商、评论家后来加上的，标题只是启发听众的想像力，引导听众的思路，对作品所要表现的内容稍作揭示。标题音乐与无标题音乐在音乐表现要素、曲式结构、内容题材方面有明显区别，判断一部作品是否是标题音乐的首要标准是看作品是否表现文学性、绘画性内容。标题音乐与文学、绘画联系的方式有两种：一是作品内容直接取材于文学或绘画，如里姆斯基·科萨科夫的交响乐《天方夜谭》、穆索尔斯基的钢琴组曲《图画展览会》、斯美塔那的交响诗《我的祖国》用；二是音乐表现作者对生活的感受或进行风景描绘，如柏辽兹的交响乐《幻想交响曲》、贝多芬的第六交响曲《田园》。 另外，标题音乐专指器乐作品，声乐作品不包括在内。标题音乐的标题一般为作者所加，标题与音乐有紧密联系，是作品思想内容的概括，是作者创作意图的展示。 十九世纪早期伟大的匈牙利作曲家、钢琴家李斯特也为标题音乐的创立和发展做出了巨大的贡献，在世界音乐史上李斯特与柏辽兹共同享有“标题音乐伟大创立者”的称号，他所创作的《但丁交响曲》和《浮士德交响曲》，与柏辽兹的《幻想交响曲》、《哈罗尔德在意大利》一样，同为浪漫主义标题交响曲形式中的杰作。更重要的是他作为浪漫派作曲家，还首创了标题交响诗这一浪漫主义交响音乐领域中的新形式。后期的作曲家将这种体裁形式发展到更加辉煌的阶段，从而人们便越来越深入细致地体会出李斯特作为这一形式的奠基人所发挥的重要作用。李斯特除了是一位杰出的作曲家以外，还是一位天才的钢琴演奏家，并以他的天才技艺和狂放气质被人们称为“钢琴之王”。李斯特作有两部交响乐和十三首交响诗，在这些作品的创作中都体现出他所主张的标题音乐的原则，他认为音乐和文学、绘画等有不可分割的内在联系，这种联系使音乐达到人的思想、感情、意志、愿望所交织成的一个焦点。因此，他力图使音乐和文学、绘画相联系，开创了单乐章交响乐体裁的先例，这一点正体现在他的创作之中，其中最著名的有：以拉马丁的诗为依据的《前奏曲》，根据歌德的同名戏剧而写的《塔索》，以古希腊神话为题材的《奥菲欧》和《普罗米修斯》，以雨果的同名诗创作的《玛捷帕》，以席勒的同名诗为基础的《理想》，取材于莎士比亚同名悲剧的《哈姆莱特》，等等。李斯特把标题音乐的创作提高到了新的水平，首创了“标题交响诗”这一新体裁。交响诗也称音诗，是一种单乐章的标题交响音乐，具有叙事性、抒情性和戏剧性的特点，被称为“诗的管弦乐”。它的题材也大多取自文学、诗歌、戏剧、绘画及历史传说，其特色是通过乐队的音响来讲述故事。 总之，标题音乐通过柏辽兹、李斯特等诸多音乐家的不懈努力，呈现出种类繁多的景象，形成了标题交响曲、音诗、音画、交响叙事曲，且增强了音乐的表现能力，丰富了音乐的表现手法，扩大了音乐的表现范围，为标题音乐的发展作出了卓越的贡献。如今的标题音乐以其独特的艺术魅力被大多数人所接受，音乐标题化手法被大多数音乐家所采纳，其通俗易解的标题内容和栩栩如生的音乐形象日益受到人们的喜爱。 百度百科 标题音乐浅析标题音乐特点 无标题音乐（absolute music） 标题音乐与之相对应的是纯音乐，也称为绝对音乐，即无标题音乐，是在音乐表17-18世纪以前的作品大多为无标题音乐。经典作品《梦见家乡与母亲》(Dreaming Of Home And Mother) 交响乐和交响曲（管弦乐）的区别交响乐（SYMPHONY） 交响乐是由多件乐器所演奏的具有交响性的音乐，它含有管弦乐、打击乐、还有一些民族乐器。 交响曲（管弦乐） 管弦乐只含有弦乐组：小提琴、中提琴、大提琴、倍大提琴；木管组：短笛、长笛、双簧管、英国管、单簧管、大管； 铜管组：小号、圆号、长号、低音号。 交响音乐不是一种特定的体裁名称，而是一类器乐体裁的总称。这类体裁的共同特征是：1、由大型的管弦乐队演奏；2、音乐内涵深刻，具有戏剧性、史诗性、悲剧性、英雄性，或者音乐格调庄重，具有叙事性、描写性、抒情性、风俗性等；3、有较严谨的结构和丰富的表现手段。 交响曲是器乐体裁的一种，是管弦乐队演奏的包含多个乐章的大型（奏鸣曲型）套曲。源于意大利歌剧序曲，海顿时定型。基本特点为：第一乐章快板，采用奏鸣曲式；第二乐章速度徐缓，采用二部曲式或三部曲式等；第三乐章速度中庸或稍快，为小步舞曲或诙谐曲；第四乐章又称”终乐章”，速度急速，采用回旋曲式奏鸣曲式等。 古典交响曲通常有四个乐章，其基本特征为： 第一乐章，奏鸣曲式，音乐活跃，充满戏剧性，由两个对立主题作呈示、展开和再现，示意矛盾的起因、发展和暂时的结果。 第二乐章，三段体或变奏曲，曲调缓慢如歌，内容往往表现生活的体验和哲理性的沉思，是交响曲抒情的中心段落。 第三乐章，常用小步舞曲或谐谑曲，音乐体现了矛盾冲突之后的闲暇、休整和娱乐。 第四乐章，多采用回旋曲式、奏鸣曲式或回旋奏鸣曲式，内容与矛盾的结果有关，常表现乐观、肯定的态度和胜利凯歌般的节日欢庆场面。 很多人把交响曲和交响乐认为是一回事，其实这就是犯了很大的一个错误。交响曲和交响乐是不同的。 和声分解和声织体 和弦中各音先后连续奏出者称分解和弦（broken chord），为和弦的装饰性或音型化处理方法之一。它常作为伴奏织体，在主调音乐中应用。18世纪上半叶，早期钢琴音乐中著名的阿尔贝蒂低音，即为分解和弦伴奏音型。也可作为曲调或声部进行的一种成分，具有旋律作用，并表示出和声内涵。 半分解和声织体 半分解和弦是将和弦音部分分解，如单音+双音、双音+双音等。 立柱式和声织体 所有的和弦音符同时发生，并以一定的节奏重复，在五线谱书写时看上去如同一根根的柱，这样的和弦结构叫柱式和弦。 奏鸣曲奏鸣曲的发展早期奏鸣曲“sonata”一词源自意大利语“sonare”，意为“鸣响”，13世纪始见于音乐用语中。 16世纪初泛指各种器乐曲，以与声乐曲的泛称康塔塔相对。如G.戈尔扎尼斯的《琉特奏鸣曲》实即两首舞曲，G.加布里埃利的《轻和重奏鸣曲》是器乐合奏曲等。继加布里埃利之后，S.罗西、M.内里、B.马里尼等意大利作曲家，均称自己所作供乐器演奏的坎佐纳为奏鸣曲。 17世纪早期，由五段或更多段对比性乐段组成的器乐合奏作品一般被认为是奏鸣曲，由此发展成巴洛克式的奏鸣曲。当时的奏鸣曲有两种形式：“室内奏鸣曲”和“教堂奏鸣曲”。三重奏鸣曲在当时十分盛行，是最常见的体裁之一。 由1件高音乐器（小提琴、长笛等）、1件低音乐器（大提琴等）和键盘乐器共同演奏的奏鸣曲，称二重奏鸣曲；由两件高音乐器（小提琴、长笛或小号等）、1件低音乐器（大提琴或维奥尔等）和键盘乐器共同演奏的奏鸣曲才被称为三重奏鸣曲；由于键盘乐器属家用性质，不居重要地位，故在计算声部时均被略去。 17世纪中叶以后，古典奏鸣曲开始出现并巩固其某些特征。其中，意大利作曲家A.科雷利对套曲形式的奠定起了重大作用，他所作的奏鸣曲均由慢—快—慢—快4个乐章组成，并交替使用复调音乐与主调音乐的写法；D.斯卡拉蒂则通过500余首奏鸣曲的创作实践，确立了古典奏鸣曲式（见奏鸣曲式）。 18世纪上半叶，独奏奏鸣曲取代了三重奏鸣曲的地位，最早为键盘乐器创作独奏奏鸣曲的作曲家是萨尔瓦托雷（Salvatore）和库瑙（J.Kuhnau），其后的独奏奏鸣曲以D.斯卡拉蒂和D.阿尔贝蒂等作曲家的作品为代表；C.P.E.巴赫确立了近代独奏奏鸣曲（古典奏鸣曲）的结构形式，包括四个乐章：第一乐章快板、奏鸣曲式；第二乐章慢板、三部曲式；第三乐章慢板、小步舞曲或诙谐曲；第四乐章快板回旋曲或回旋奏鸣曲。 18世纪下半叶，海顿、莫扎特省去了以往奏鸣曲中的第二乐章或第三乐章，确立了三个乐章的奏鸣曲形式（快板—行板—快板）；在贝多芬的发展下，奏鸣曲体裁又向前迈了一步，就乐章数量来看他的作品包括三个乐章，有的扩展为四个乐章（创用小步舞曲，稍后用谐谑曲作为第三乐章），在发展规模上接近交响曲结构；他的32首钢琴奏鸣曲为这种体裁做出了历史性的重要贡献，标志着奏鸣曲进入成熟的发展时期。 19世纪浪漫主义时期，奏鸣曲始终是由一件或两件乐器演奏的最重要的器乐体裁，它展现了浪漫主义音乐的特征，主要表现在作品的史诗性、标题性、主题的发展性、变奏性和歌唱性等方面；乐章的数目有所发展，多乐章、单乐章（李斯特首创）不一。该时期对奏鸣曲做出重要贡献的有舒伯特、肖邦、舒曼、李斯特、勃拉姆斯等作曲家。 曲式结构通常所说的奏鸣曲式，是指维也纳古典乐派时期由3个部分组成的奏鸣曲式。它的结构由“呈示部”、“展开部”与“再现部”三大段依序组成： 呈示部 呈示部是这一结构形式的基础，它呈示两个主题，第一主题在主调上，第二主题通常在属调上，两个主题不仅有情感上的对比，还有调性上的对比。呈示部前可加引子； 发展部 发展部通过各种手法，充分发挥呈示部第一、二主题中具有特征的因素，主要通过调性、调式的对置，复调音乐与主调音乐的处理等，将主题变化成为各种形式，从各个方面进一步体现主题的内涵； 再现部 再现呈示部，但第二主题必须回到主调，使第一、第二主题在调性上获得一致，形成了一个完整的、统一的整体，使主题形象更加完美、突出，曲终可加尾声。只包含呈示部和再现部而没有展开部的奏鸣曲式是它的变体。现代作品往往不墨守上述各种原则。 套曲和组曲套曲套曲是个大概念，凡是由几个独立段落构成的音乐作品都叫作套曲，像交响曲、协奏曲就都属于套曲结构，组曲也是套曲中的一种。构成套曲的各段（或各乐章）有时只是一种很松散的联合，但有时也存在严格的整体结构，有的作品甚至各乐章采用同一个主题，以取得完整的效果。在器乐套曲中，最重要的当推奏鸣曲，见奏鸣曲。 组曲组曲是各种器乐套曲中最早出现的形式，现在分成古组曲和现代组曲两种类型。 古组曲 古组曲是由舞曲发展出来的。早在十五世纪，欧洲的作曲家们就已经不满足那些短小的舞曲。他们将几首舞曲的调性统一起来，然后按照对比的原则、根据不同的风格和速度将它们有机地联缀在一起。由于它是由舞曲联缀而成，所以又称“舞蹈组曲”。 构成古组曲的舞曲有很多种，常见的如阿勒芒德舞曲、波洛奈兹舞曲、库朗特舞曲、加沃特舞曲、吉格舞曲等等。这些舞曲在十五、十六世纪都曾经广泛地流行于欧洲的民间和宫廷。 古组曲所包含的舞曲的数目起先是不固定的，但通常为四首以上。到巴罗克时期，形成由四首舞曲组成的固定形式。 它们的顺序是：阿勒芒德舞曲（四拍子，中速，庄重）— 库朗特舞曲（三拍子，稍快，活泼）—萨拉班德舞曲（三拍子，慢速，平稳）—（有时插入其他舞曲）— 吉格舞曲（三拍子，快速，跳跃）。由于这种形式的古组曲在巴洛克时期定型，因此又叫作“巴洛克组曲”。 现代组曲 现代组曲在结构原则上与巴洛克组曲没有根本的区别，只是形式更加自由。在现代组曲中，舞曲已经不再是唯一的材料。 十九世纪浪漫乐派的作曲家常常从芭蕾、戏剧、歌剧以至文学作品中取材，写成标题性的交响组曲；例如柴科夫斯基的《天鹅湖组曲》（取自他的舞剧《天鹅湖》）、格里格的《培尔•金特组曲》（取自他为话剧《培尔•金特》所作的配乐）、里姆斯基•科萨科夫的《舍赫拉查达》（以阿拉伯故事集《天方夜潭》为素材）、比捷的《阿莱城姑娘》（取自他为同名话剧作的配乐）等，都是这种富有戏剧性的交响组曲的佳作。]]></content>
  </entry>
  <entry>
    <title><![CDATA[巧克力推荐]]></title>
    <url>%2F2018%2F11%2F07%2Flife%2F%E5%B7%A7%E5%85%8B%E5%8A%9B%2F</url>
    <content type="text"><![CDATA[黑巧克力 Amedei 意大利品牌 Amedei，制作巧克力所选用的原料大多来自于其直营的可可庄园。Amedei 的黑巧品质很高，尤以 Chuao 出名——这是委内瑞拉境内最具传奇性的梦幻可可产区。 Akesson 英国品牌 Akesson（简称AK），是近年非常流行的品牌，它的巧克力经常获得AOC（Academy of Chocolate Awards）颁发的奖项，而 AK 家的 “Single Estate Chocolate”（单一种植园巧克力）系列，更是拿奖拿到手软。推荐尝试他家的黑巧，很多获奖款！ Bernachon 仅在法国有店的 Bernachon 所制作的巧克力排块选用产地里最优质的可可，且使用 10 个单源产地可可混合而成，极为考验制作人的技艺。 牛奶巧克力 Akesson’s 野生胡椒 AK 的这款巧克力添加了 2% 的 Voatisperifery 胡椒，味道十分独特——它能带给你的不仅仅是丝滑和甜美。 Pralus Melissa 法国的巧克力品牌 Pralus 于 1948 年在靠近里昂的城市罗阿讷（Roanne）诞生，由 Auguste Pralus 创立，他曾在 1955 年得到法国工艺大奬的最佳巧克力工匠 （Meilleur Ouvrier de France）。该店出品的牛奶巧克力 Melissa 使用 criollo 可可豆制成，曾在2014年获得金奖。 白巧克力 瑞士莲 Lindt 瑞士莲（Lindt &amp; Sprüngli）是一家瑞士巧克力与糖果公司，于1845年由David Sprüngli-Schwarz(大卫·史宾利-史瓦兹)与其子Rudolf Sprüngli-Ammann(鲁道夫·史宾利-阿曼)创立。 Akesson’s 43%白巧克力 AK 出品的白巧克力，使用单源可可豆提取可可脂，是马达加斯加 Bejofo ester 庄园第一款单源白巧克力。 手工巧克力 小山进（日本） Teuscher（瑞士） Patrick Roger（法国）]]></content>
      <categories>
        <category>非原创</category>
        <category>生活</category>
        <category>零食</category>
      </categories>
      <tags>
        <tag>巧克力</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Performance Tuning]]></title>
    <url>%2F2018%2F11%2F07%2Flinux%2Fperformance-tuning%2Flinux-performance-tuning%2F</url>
    <content type="text"><![CDATA[前言Purpose of Performance Tuning 将系统调节成扮演某个角色。譬如：数据库服务器、WEB服务器、文件服务器、邮件服务器等等。 找到并缓解系统瓶颈 调优指标：响应速度，吞吐量 CPU、内存等硬件在最优情况下等达到最高的性能，你必须清楚。 Required Skills Understand both hardware and software Collecting and analysis of measurable relevant data about a performance problem Set proper expectations 5 years full time system management experience Tuning Efficiency（调优效率） Business Level Tuning Ask right question: “Reduce CPU utilization” or “Business goal” Adjust workflow（调整业务的流程，减少对系统的不必要请求） Removing unused services PC Smart Card Daemon Buletooth and hidd Do i really need the default cron jobs? /etc/cron.daily/makewhatis.cron /etc/cron.daily/mlocate.cron Application Level Tuning Disable or defer expensive operations until analysis?（禁用或延迟对系统而言“很贵的”操作） Disable reverse name lookups Set loglevel to warn for most production daemons Is syslogd a bottleneck? Daemon uses fsync() to flush every file write（系统为保证日志文件不丢失，会立刻调用fsync方法将数据写入磁盘） Disable by prepending hyphen to name of log file in /etc/rsyslog.conf（在日志文件加“-”号，该日志会滞后写入） Tips：应用层调优，调的是应用程序本身。譬如你使用nginx、nfs，它们本身有大量的参数可用来调优。在应用层调优远远优于内核调优。 Kernel Level Tuning(RH442) 从上往下优化空间越来越小，效果越来越不明显。譬如目前你的WEB Server是apache，调优前首先考虑是否非得使用apache，我们的业务是否是高并发，能不能换成nginx。能够在顶层解决问题，尽量不要希望在底层去解决。 总结 一个命令敲下去，性能提高10%、20%，这是不切合实际的。红帽操作系统已经调优过了，我们是为了某个特定的角色再进行调优。 不同角色的系统有不同调优的参数，不能指望一个参数搞定所有事情。 物理级别的缺陷，比如硬盘、网卡等由于寿命原因性能大幅下降，则系统层面调优见效甚微。 Understand HardwareComputer System Architecture CPU 运算器 控制器（指令、数据存储过程） 寄存器（Register） North bridge（寻址） CPUX86架构机器三个特点（RH442） I/O Address X86架构CPU把外设寄存器看做是一个独立的地址空间，访问内存的指令不能用来访问这些外设寄存器，而需要用专用的指令（如IN、OUT指令），称为“I/O端口”。不同外设使用不同“I/O端口”，PCI总线就能知道是哪个外设了，当然“I/O端口”会被消耗完。 Power PC、ARM的CPU把外设寄存器看做是内存的一部分、寄存器参与内存统一编址，通过一般的内存指令来访问这些外设寄存器，称为“I/O内存”。 IRQ（中断请求） DMA（直接内存访问） DMA主要功能是传输数据，但是不需要占用CPU（不需要中断）。传输数据从外设到存储器或者从存储器到存储器。 在实现DMA传输时，是由DMA控制器直接掌管总线，因此，存在着一个总线控制权转移问题。即DMA传输前，CPU要把总线控制权交给DMA控制器，而在结束DMA传输后，DMA控制器应立即把总线控制权再交回给CPU。 完整的DMA传输过程必须经过下面的4个步骤 ： DMA请求 CPU对DMA控制器初始化，并向I/O接口发出操作命令，I/O接口提出DMA请求。 DMA响应 DMA控制器对DMA请求判别优先级及屏蔽，向总线裁决逻辑提出总线请求。当CPU执行完当前总线周期即可释放总线控制权。此时，总线裁决逻辑输出总线应答，表示DMA已经响应，通过DMA控制器通知I/O接口开始DMA传输。 DMA传输 DMA控制器获得总线控制权后，CPU即刻挂起或只执行内部操作，由DMA控制器输出读写命令，直接控制RAM与I/O接口进行DMA传输。在DMA控制器的控制下，在和外部设备之间直接进行数据传送，在传送过程中不需要的参与。开始时需提供要传送的数据的起始位置和数据长度。 DMA结束 当完成规定的成批数据传送后，DMA控制器即释放总线控制权，并向I/O接口发出结束信号。当I/O接口收到结束信号后，一方面停止I/O设备的工作，另一方面向CPU提出中断请求，使CPU从不介入的状态解脱，并执行一段检查本次DMA传输操作正确性的代码。最后，带着本次操作结果及状态继续执行原来的程序。 由此可见，DMA传输方式无需CPU直接控制传输，也没有中断处理方式那样保留现场和恢复现场的过程，通过硬件为RAM与I/O设备开辟一条直接传送数据的通路，使CPU的效率大为提高。 参考：DMA原理 扩展小知识： 内存中起始16M空间，是留给DMA使用的，用于把数据装载进内存空间低地址空间。内存中另有1M空间是给BIOS预留，计算机有自举功能，用于初始化足够的软件来查找并加载功能完整的操作系统。 查看CPU 总览 123456789101112131415161718192021222324[root@yadoom ~]# lscpu Architecture: x86_64 #x86架构CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 40 #逻辑CPU个数On-line CPU(s) list: 0-39Thread(s) per core: 2 #每核的线程数Core(s) per socket: 10 #每颗CPU的核数Socket(s): 2 #物理CPU个数NUMA node(s): 2 # NUMA节点数Vendor ID: GenuineIntelCPU family: 6Model: 79Model name: Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHzStepping: 1CPU MHz: 1200.093BogoMIPS: 4805.86Virtualization: VT-xL1d cache: 32K #一级数据缓存L1i cache: 32K #一级指令缓存L2 cache: 256K #二级缓存L3 cache: 25600K #三级缓存NUMA node0 CPU(s): 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38NUMA node1 CPU(s): 1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39 核数 12345678[root@yadoom ~]# grep CPU /proc/cpuinfomodel name : Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHzmodel name : Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz......model name : Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHzmodel name : Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz[root@yadoom ~]# grep CPU /proc/cpuinfo | wc -l40 CPU架构 SMP架构：Symmetric Multi-Processor 大多数早期的单处理机系统的设计为让每个 CPU 到每个内存位置都使用同一逻辑路径（一般是平行总线）。这样每次 CPU 访问任意位置的内存时与其他系统中的 CPU 对内存的访问消耗的时间是相同的。此类架构就是我们所说的对称多处理器（SMP）系统。SMP 适合 CPU 数较少的系统，但一旦 CPU 计数超过某一点（8 或者 16），要满足对内存的平等访问所需的平行 trace 数就会使用过多的板载资源，留给外设的空间就太少。 UNMA架构：Non-Uniform Memory Access 不是为每个处理器包提供对等的内存访问，而是让每个包/插槽组合有一个或者多个专用内存区以便提供高速访问。每个插槽还有到另一个插槽的互联以便提供对其他插槽内存的低速访问。 下图中 CPU0 访问左边的内存条大约需要三个时钟周期：一个周期是将地址发给内存控制器，一个周期是设置对该内存位置的访问，一个周期是读取或者写入到该位置。但 CPU1 可能需要 6 个时钟周期方可访问内存的同一位置，因为它位于不同的插槽，必须经过两个内存控制器：插槽 1 中的本地内存控制器和插槽 0 中的远程内存控制器。如果在那个位置出现竞争（即如果有一个以上 CPU 同时尝试访问同一位置），内存控制器需要对该内存进行随机且连续的访问，所以内存访问所需时间会较长。添加缓存一致性（保证本地 CPU 缓存包含同一内存位置的相同数据）会让此过程更为复杂。 扩展小知识：当CPU有多颗时，物理CPU常见通讯方法有三种 FSB（传统的前端总线，常用于PC机） QPI(intel) HyperTransport(AMD) MPP架构：Massive Parallel Processing 大规模并行处理系统，它由多个 SMP 服务器通过节点互联网络连接，协同工作，完成相同的任务，从用户的角度来看是一个服务器系统。每个节点内的CPU都有自己私有的资源，如总线，内存，硬盘等。在每个节点内都有操作系统和管理数据库的实例复本。这种结构最大的特点在于不共享资源。 在 MPP 系统中，每个 SMP 节点也可以运行自己的操作系统、数据库等，是一种完全无共享 (Share Nothing) 结构。但和 NUMA 不同的是，它不存在异地内存访问的问题。换言之，每个节点内的 CPU 不能访问另一个节点的内存。节点之间的信息交互是通过节点互联网络实现的，这个过程一般称为数据重分配 (Data Redistribution) 。节点互联网仅供 MPP 服务器内部使用，对用户而言是透明的。 Numa Architecture查看Numa node123456789101112[root@yadoom ~]# numactl --hardwareavailable: 2 nodes (0-1) # 当前机器有2个NUMA node，编号0、1node 0 cpus: 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30node 0 size: 32722 MB # 物理内存大小node 0 free: 2352 MB # 当前free内存大小node 1 cpus: 1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31node 1 size: 32768 MBnode 1 free: 12314 MBnode distances: # node距离，可以简单认为Node内部访问及跨Node访问的成本node 0 1 0: 10 20 # 由此可知跨node访问内存的成本是 内部访问的2倍 1: 20 10 查看node node0包含的CPU 123[root@yadoom ~]# ls -l /sys/devices/system/node/node0/cpu0/ cpu12/ cpu16/ cpu2/ cpu22/ cpu26/ cpu30/ cpu6/ cpulist cpu10/ cpu14/ cpu18/ cpu20/ cpu24/ cpu28/ cpu4/ cpu8/ cpumap /sys/devices/system/cpu 系统的 CPU 是如何互相连接的信息。 /sys/devices/system/node 系统中 NUMA 节点以及那些节点间相对距离的信息。 查看cpu cache123456[root@yadoom ~]# ls -l /sys/devices/system/cpu/cpu0/cache/total 0drwxr-xr-x 2 root root 0 Nov 10 2017 index0 # 1级数据cachedrwxr-xr-x 2 root root 0 Nov 3 2017 index1 # 1级指令cachedrwxr-xr-x 2 root root 0 Nov 3 2017 index2 # 2级cachedrwxr-xr-x 2 root root 0 Nov 10 2017 index3 # 3级cache, 对应cpuinfo里的cache 目录里的文件是cache信息描述，以本机的cpu0/index0为例简单解释一下： 文件 内容 说明 type Data 数据cache，如果查看index1就是Instruction Level 1 L1 Size 32K 大小为32K coherency_line_size 64 64 4 128=32K physical_line_partition 1 ways_of_associativity 4 number_of_sets 128 shared_cpu_map 00000101 表示这个cache被CPU0和CPU8 share 解释一下shared_cpu_map内容的格式，表面上看是2进制，其实是16进制表示，每个bit表示一个cpu，1个数字可以表示4个cpu截取00000101的后4位，转换为2进制表示。 CPU id 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 0×0101的2进制表示 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0101表示cpu8和cpu0，即cpu0的L1 data cache是和cpu8共享的。 再看一下index3 shared_cpu_map的例子 12# cat /sys/devices/system/cpu/cpu0/cache/index3/shared_cpu_map00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000f0f CPU id 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 0x0f0f的2进制表示 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 cpu0,1,2,3和cpu8,9,10,11共享L3 cache。 查看numa状态12345678[root@yadoom ~]# numastat node0 node1numa_hit 1011487518 716368222numa_miss 0 145365467numa_foreign 145365467 0interleave_hit 20673 20631local_node 1011487341 716343592other_node 177 145390097 上述可知node 0的unma_miss过高，可考虑用numactl将进程和CPU绑定。详见CPU调优章节。 参数 说明 numa_hit 为这个节点成功的分配尝试数。 numa_miss 由于在目的节点中内存较低而尝试为这个节点分配到另一个节点的数目。每个 numa_miss 事件都在另一个节点中有对应的 numa_foreign 事件。 numa_foreign 最初要为这个节点但最后分配个另一个节点的分配数。每个 numa_foreign 事件都在另一个节点中有对应的 numa_miss 事件。 interleave_hit 成功分配给这个节点的尝试交错策略数。 local_node 这个节点中的进程成功在这个节点中分配内存的次数。 other_node 这个节点中的进程成功在另一个节点中分配内存的次数。 1234567[root@yadoom ~]# numactl --showpolicy: defaultpreferred node: currentphyscpubind: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 cpubind: 0 1nodebind: 0 1membind: 0 1 查看内存numa node分布12cat /proc/&lt;pid&gt;/numa_mapscat /proc/$(pidof pname|cut -d "" -f1)/numa_maps 查看线程run在哪个processor1234top -p $(pidof pname|sed -e 's/ /,/g')在默认配置下不显示线程信息，需要进入Top后按“shift+H”，打开线程显示。另外，如果没有P列，还需要按“f”，按“j”，添加，这一列显示的数字就是这个线程上次run的processor id。 https://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/https://software.intel.com/en-us/articles/intel-64-architecture-processor-topology-enumeration/ numadnumad 是一个自动 NUMA 亲和性管理守护进程，它监控系统中的 NUMA 拓扑以及资源使用以便动态提高 NUMA 资源分配和管理（以及系统性能）。 numad 不会在进程只运行几分钟或者不会消耗很多资源时改进性能。 有连续不可预测内存访问的系统，比如大型内存中的数据库也不大可能从 numad 使用中受益。 CPU CacheLevels of CPU Caches Level 1 private cache(on cpu chip) SRAM(static memory)：集成度低（存储相同的数据，静态RAM的体积是动态RAM的6倍），价格高（同容量的静态RAM是动态RAM的四倍） Level 2 private or shared cache(on cpu chip) DRAM(high speed dynamic memory) Level 3 private or shared cache(usually on mainboard) shared between cores inside a CPU socket Level 4 fully shared cache shared between CPU sockets Cache Memory Types内存和缓存的关联地址。 Direct Mapped Cache a memory location can be cached into one cache line.（一个内存地址，只能被映射到缓存的一个区域。） Full Associative Cache a memory location can be cached into any cache line.（一个内存地址，可以被映射到缓存所有区域。） n-Way Associative Cache Fair,most used, a memory location can be cached into any one of n cache lines. 12345678910111213141516171819202122[root@kvm-2 ~]# x86info -cx86info v1.25. Dave Jones 2001-2009Feedback to &lt;davej@redhat.com&gt;.Found 8 CPUs--------------------------------------------------------------------------CPU #1EFamily: 0 EModel: 3 Family: 6 Model: 62 Stepping: 4CPU Model: Unknown model. Processor name string: Intel(R) Xeon(R) CPU E5-2609 v2 @ 2.50GHzType: 0 (Original OEM) Brand: 0 (Unsupported)Number of cores per physical package=16Number of logical processors per socket=32Number of logical processors per core=2APIC ID: 0x0 Package: 0 Core: 0 SMT ID 0Cache infoTLB info Instruction TLB: 4K pages, 4-way associative, 128 entries. # 4路关联 Data TLB: 4KB pages, 4-way associative, 64 entries 64 byte prefetching.Found unknown cache descriptors: 63 76 ca ff -------------------------------------------------------------------------- 查看CPU Cache12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788[root@yadoom ~]# lscpu Architecture: x86_64 #x86架构CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 8 #逻辑CPU个数On-line CPU(s) list: 0-7Thread(s) per core: 1 #每核的线程数Core(s) per socket: 4 #每颗CPU的核数Socket(s): 2 #物理CPU个数NUMA node(s): 2 # NUMA节点数Vendor ID: GenuineIntelCPU family: 6Model: 62Stepping: 4CPU MHz: 2499.904BogoMIPS: 4999.28Virtualization: VT-xL1d cache: 32K #一级数据缓存L1i cache: 32K #一级指令缓存L2 cache: 256K #二级缓存L3 cache: 10240K #三级缓存NUMA node0 CPU(s): 0,2,4,6NUMA node1 CPU(s): 1,3,5,7[root@yadoom ~]# lscpu -p# The following is the parsable format, which can be fed to other# programs. Each different item in every column has an unique ID# starting from zero.# CPU,Core,Socket,Node,,L1d,L1i,L2,L3 # “Node”表示NUMA nodes0,0,0,0,,0,0,0,01,1,1,1,,1,1,1,12,2,0,0,,2,2,2,03,3,1,1,,3,3,3,14,4,0,0,,4,4,4,05,5,1,1,,5,5,5,16,6,0,0,,6,6,6,07,7,1,1,,7,7,7,1[root@yadoom ~]# dmidecode -t 7# dmidecode 2.11SMBIOS 2.7 present.Handle 0x0700, DMI type 7, 19 bytesCache Information Socket Designation: Not Specified Configuration: Enabled, Not Socketed, Level 1 Operational Mode: Write Through Location: Internal Installed Size: 128 kB #一级缓存（32k * 4） Maximum Size: 128 kB Supported SRAM Types: Unknown Installed SRAM Type: Unknown Speed: Unknown Error Correction Type: Single-bit ECC System Type: Data Associativity: 8-way Set-associativeHandle 0x0701, DMI type 7, 19 bytesCache Information Socket Designation: Not Specified Configuration: Enabled, Not Socketed, Level 2 Operational Mode: Write Through Location: Internal Installed Size: 1024 kB #二级缓存（256k * 4） Maximum Size: 1024 kB Supported SRAM Types: Unknown Installed SRAM Type: Unknown Speed: Unknown Error Correction Type: Single-bit ECC System Type: Unified Associativity: 8-way Set-associativeHandle 0x0702, DMI type 7, 19 bytesCache Information Socket Designation: Not Specified Configuration: Enabled, Not Socketed, Level 3 Operational Mode: Write Back Location: Internal Installed Size: 10240 kB #与lscpu数值一样，说明4核共享三级缓存 Maximum Size: 10240 kB Supported SRAM Types: Unknown Installed SRAM Type: Unknown Speed: Unknown Error Correction Type: Single-bit ECC System Type: Unified Associativity: 20-way Set-associative 由上输出可得知该服务器的L1，L2是每个核心独享的，L3是共享的。 疑问 CPU如何读取RAM中的数据？ 答：使用CPU Cache(缓存)。CPU将数据从RAM拷贝到L3缓存，再一次拷贝到L2缓存、L1数据缓存，最后到寄存器中。 CPU Cache置换算法 置换算法影响因素：程序局部性 空间局部性: 时间局部性:数据很可能会再短时间内被再次访问。 LRU(Least recently used) 最近最少使用算法，这个缓存算法将最近使用的条目存放到靠近缓存顶部的位置。当一个新条目被访问时，LRU将它放置到缓存的顶部。当缓存达到极限时，较早之前访问的条目将从缓存底部开始被移除。 MRU(Most recently used) 最近最常使用算法，将使用时间距离现在最近的那条记录替换掉。 CPU如何更新数据？ 答：CPU依次更新L1、L2、L3缓存对应的数据，最后更新RAM。 CPU Cache写机制 write through cpu向cache写入数据时，同时向memory(后端存储)也写一份，使cache和memory的数据保持一致。优点是简单；缺点是每次都要访问memory，速度比较慢。 write back cpu更新cache时，只是把更新的cache区标记一下，并不同步更新memory。当cache要被置换出去时，才去更新memory(后端存储)。优点是数据写入速度快，因为不需要写存储；缺点是一旦更新后的数据未被写入存储时出现系统掉电的情况，数据将无法找回。 Memory Memory size,max allowed 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@yadoom ~]# free total used free shared buffers cachedMem: 90743596 23288228 67455368 0 684452 2938648-/+ buffers/cache: 19665128 71078468Swap: 26214392 0 26214392[root@yadoom ~]# more /proc/meminfo MemTotal: 263860344 kB # 已经减去了显卡占用的内存MemFree: 206924460 kBMemAvailable: 248609828 kBBuffers: 145604 kBCached: 51754488 kBSwapCached: 0 kBActive: 45933660 kBInactive: 7115240 kBActive(anon): 8130140 kBInactive(anon): 4851368 kBActive(file): 37803520 kBInactive(file): 2263872 kB[root@yadoom ~]# dmidecode -t 17# dmidecode 2.11SMBIOS 2.7 present.Handle 0x1100, DMI type 17, 34 bytesMemory Device Array Handle: 0x1000 Error Information Handle: Not Provided Total Width: 72 bits Data Width: 64 bits Size: 8192 MB # 内存大小 Form Factor: DIMM Set: 1 Locator: DIMM_A1 Bank Locator: Not Specified Type: DDR3 # DDR3代 Type Detail: Synchronous Registered (Buffered) Speed: 1333 MHz # 时钟频率 Manufacturer: 00CE04B300CE Serial Number: 4400B1EA Asset Tag: 01104611 Part Number: M393B1K70CH0-YH9 Rank: 2 Configured Clock Speed: 1333 MHz...... bandwidth and letency DDR2(2 bits),DDR3(4 bits),DDR4(8 bits) Bandwidth = Clock rate(时钟频率) 4(DDR3) 2(Double) * bits / 8（Double就是D，脉冲升频降会各取一次数据。带宽无需手动计算，内存卡会标识PC xxxxMB） Letency(wait time before read again,in ns)读取内存时，要等待的时间。动态内存需要电门不停的刷，所以读取数据需要时间。 ECC(slower,safer) Corrects single-bit errors Detects multiple-bit errors Method of memory accessing UMA,NUMA Storage Type of storage used mechanical magnetic platters（机械磁盘） SSD devices（固态磁盘） Hardware RAID Level stripe depth（条带深度） stripe width（条带宽度） stripe size = stripe depth × stripe width Direct-attached Storage（直连存储） SATA,SAS,IDE SCSI,Fibre Channel,ISCSI Bandwidth,latency,multipath 磁盘架构 架构概述 硬盘中包含多个硬盘盘片，硬盘盘片为圆形，每个硬盘盘片都有一个可以读写的磁头(Head)，将这个磁头固定，使硬盘盘片旋转一周，所走轨迹就是磁道(Track)。硬盘内所有盘片的相同磁道号的集合成为磁柱(Cylinder)。每一磁道被划分成许多区域，每个区域叫一个扇区(Sector)。扇区是硬盘的最小存储物理量，一个扇区的存储容量大约是512字节(约0.5K)。 geometry geometry应该翻译为几何数据，其实就是指的CHS(Cylinder、Head、Sector/Track) 。 Cylinder（每面盘片上有几条磁道） Head（磁头数量，也就是几面盘片。） Sector/Track（每条磁道上有几个扇区） sector block Capacity CLV(Constant Linear Velocity) CAV(Constant Angular Velocity) Zoned CAV 扩展小知识： Linux里文件的文件名、文件属性、文件内容是分别存储的：文件名存放在目录项（即dentry）中，文件属性存放在inode中，一般情况下，每个inode占用128Bity磁盘空间，文件内容存放在block中。每个block最多存放一个文件，而当一个block存放不下的情况下，会占用下一个block。 1234567891011121314# 总容量：heads * cylinders * sectors * Sector size[root@localhost ~]# fdisk -l /dev/sdaDisk /dev/sdd: 299.4 GB, 299439751168 bytes255 heads, 63 sectors/track, 36404 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00056494......[root@localhost ~]# tune2fs -l /dev/sda1 | grep BlockBlock count: 204800Block size: 1024Blocks per group: 8192 123456[root@localhost ~]# vmstat 1 3procs -----------memory---------- ---swap-- ----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 260352448 34480 2212952 0 0 0 1 2 3 0 0 100 0 0 0 0 0 260352192 34480 2212956 0 0 0 0 124 177 0 0 100 0 0 0 0 0 260352192 34480 2212956 0 0 0 0 27 44 0 0 100 0 0 bi bo 的单位是块，但是它不是操作系统里的那个块，它表示物理磁盘的块（sector，扇区），每个扇区 512 字节。 磁盘外圈速度比里圈速度快得多，所以操作系统默认将swap分区分配在里圈。 磁盘速度一般都指Burst speed（顺序读写）速率。 磁盘类型 IDE（并口） IDE（Integrated Drive Electronics电子集成驱动器）的缩写，它的本意是指把控制器与盘体集成在一起的硬盘驱动器，是一种硬盘的传输接口，它有另一个名称叫做ATA（Advanced Technology Attachment），这两个名词都有厂商在用，指的是相同的东西。 IDE的规格后来有所进步，而推出了EIDE（Enhanced IDE）的规格名称，而这个规格同时又被称为Fast ATA。所不同的是Fast ATA是专指硬盘接口，而EIDE还制定了连接光盘等非硬盘产品的标准。而这个连接非硬盘类的IDE标准，又称为ATAPI接口。而之后再推出更快的接口，名称都只剩下ATA的字样，像是Ultra ATA、ATA/66、ATA/100等。 SATA（串口） SATA（Serial ATA）口的硬盘又叫串口硬盘。2001年，由Intel、APT、Dell、IBM、希捷、迈拓这几大厂商组成的Serial ATA委员会正式确立了Serial ATA 1.0规范。 SATA接口需要硬件芯片的支持，例如Intel ICH5(R)、VIA VT8237、nVIDIA的MCP RAID和SiS964，如果主板南桥芯片不能直接支持的话，就需要选择第三方的芯片，例如Silicon Image 3112A芯片等，不过这样也就会产生一些硬件性能的差异，并且驱动程序也比较繁杂。 SATA的优势：支持热插拔，传输速度快，执行效率高。 SCSI（小型计算机系统专用接口） SCSI的英文全称为“Small Computer System Interface”（小型计算机系统接口），是同IDE（ATA）完全不同的接口，IDE接口是普通PC的标准接口，而SCSI并不是专门为硬盘设计的接口，是一种广泛应用于小型机上的高速数据传输技术。SCSI接口具有应用范围广、多任务、带宽大、CPU占用率低，以及热插拔等优点，但较高的价格使得它很难如IDE硬盘般普及，因此SCSI硬盘主要应用于中、高端服务器和高档工作站中。 SAS（就是串口的SCSI接口） SAS(Serial Attached SCSI)即串行连接SCSI，是新一代的SCSI技术。和现在流行的Serial ATA(SATA)硬盘相同，都是采用串行技术以获得更高的传输速度，并通过缩短连结线改善内部空间等。SAS是并行SCSI接口之后开发出的全新接口。此接口的设计是为了改善存储系统的效能、可用性和扩充性，并且提供与SATA硬盘的兼容性。 FC（光纤通道） 光纤通道的英文拼写是Fiber Channel，和SCIS接口一样光纤通道最初也不是为硬盘设计开发的接口技术，是专门为网络系统设计的，但随着存储系统对速度的需求，才逐渐应用到硬盘系统中。光纤通道硬盘是为提高多硬盘存储系统的速度和灵活性才开发的，它的出现大大提高了多硬盘系统的通信速度。光纤通道的主要特性有：热插拔性、高速带宽、远程连接、连接设备数量大等。 SSD（固态硬盘） 固态硬盘（Solid State Disk或Solid State Drive），也称作电子硬盘或者固态电子盘，是由控制单元和固态存储单元（DRAM或FLASH芯片）组成的硬盘。固态硬盘的接口规范和定义、功能及使用方法上与普通硬盘的相同，在产品外形和尺寸上也与普通硬盘一致。由于固态硬盘没有普通硬盘的旋转介质，因而抗震性极佳。其芯片的工作温度范围很宽（-40~85℃）。 由于固态硬盘技术与传统硬盘技术不同，所以产生了不少新兴的存储器厂商。厂商只需购买NAND存储器，再配合适当的控制芯片，就可以制造固态硬盘了。新一代的固态硬盘普遍采用SATA-2接口。 查看磁盘1234567891011121314151617181920212223242526272829[root@yadoom ~]# fdisk -l /dev/sda Disk /dev/sda: 4000.8 GB, 4000787030016 bytes255 heads, 63 sectors/track, 486401 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000[root@yadoom ~]# lspci......00:1f.0 ISA bridge: Intel Corporation C600/X79 series chipset LPC Controller (rev 05)00:1f.2 SATA controller: Intel Corporation C600/X79 series chipset 6-Port SATA AHCI Controller (rev 05)......[root@yadoom ~]# hdparm -I /dev/sda/dev/sda:ATA device, with non-removable media Model Number: ST1000NM0033-9ZM173 # 希捷1T Serial Number: Z1W3VQXC Firmware Revision: GA0A Transport: Serial, SATA Rev 3.0Standards: Supported: 9 8 7 6 5 Likely used: 9......[root@yadoom ~]# dmesg |grep -C5 SATA SSD Electronic disk, no moving mechanical(机械) components No startup time Very low latency Potentially longer life time（尽可能延长寿命） Wear leveling（磨损平衡）:闪存寿命是以P/E（完全擦写）次数来计算的，而WL就是确保闪存内每个块被写入的次数相等的一种机制。 Parameter TBW 在 SSD 使用寿命结束之前指定工作量可以写入 SSD 的总数据量。 DWPD 在保固期内（或不同的数年时段内）每天可以写入硬盘用户存储容量的次数。 DWPD = (固态硬盘的 TBW (TB) P/E) / (365 天 年数 * 固态硬盘用户容量 (GB)) SSD Types固态硬盘就是靠NAND Flash闪存芯片存储数据的，这点类似于我们常见的U盘。NAND Flash根据存储原理分为三种，SLC、MLC、TLC。 SLC Single-Level Cell ，即1bit/cell（1个存储器储存单元可存放1 bit的数据），速度快寿命长，价格超贵（约MLC 3倍以上的价格），约10万次擦写寿命 MLC Multi-Level Cell，即2bit/cell，速度一般寿命一般，价格一般，约1000–3000次擦写寿命 TLC Trinary-Level Cell，即3bit/cell，也有Flash厂家叫8LC，速度慢寿命短，价格便宜，约1000次擦写寿命。 单位容量的存储器，可以存储更多的数据，所以TLC每百万字节生产成本是最低的。 案例：计算256G的TLC固态硬盘的使用寿命。 假设该硬盘每天读取100G数据，256G*1000/356/100G=7.19（年） SSD Garbage Collection 上图SSD中有两个空的（erased）的Block X和Block Y, 每个Block有12个Pages; 首先在Block X中写入4个Pages(A, B, C, D); 接着再向Block X中写入新的4个pages(E, F, G, H), 同时写入PageA-D的更新数据（A’, B’, C’, D’), 这时PageA-D变为失效数据（invalid）; 为了向PageA-D的位置写入数据，需要将E, F, G, H, A’, B’, C’, D’ 8个pages先搬到Block Y中, 之后再把Block X erase掉，这个过程就为GC。 Nand flash 以Page为单位读写数据，而以Block为单位擦除数据。 不过，由于GC的过程增加了数据的读写过程，势必会对SSD的performance的产生一定的影响，所以GC发生的条件与触发点很关键。 GC触发条件大致有3点： Spare Block（）备用块太少 Wear leveling 处理ECC错误Block SSD Trim操作系统删除数据时，Windows只会做个标记，说明这里已经没东西了，等到真正要写入数据时再来真正删除，并且做标记这个动作会保留在磁盘缓存中，等到磁盘空闲时再执行；Linux只会把inode table回收。 所以对于非空的page，SSD在写入前必须先进行一次Erase，则写入过程为read-erase-modify-write:将整个block的内容读取到cache中，整个block从SSD中Erase,要覆写的page写入到cache的block中，将cache中更新的block写入闪存介质，这个现象称之为写入放大(write amplification)。 为了解决这个问题，SSD开始支持TRIM，TRIM功能使操作系统得以通知SSD哪些页不再包含有效的数据。 当Windows识别到SSD并确认SSD支持Trim后，在删除数据时，会不向硬盘通知删除指令，只使用Volume Bitmap来记住这里的数据已经删除。Volume Bitmap只是一个磁盘快照，其建立速度比直接读写硬盘去标记删除区域要快得多。这一步就已经省下一大笔时间了。然后再是写入数据的时候，由于NAND闪存保存数据是纯粹的数字形式，因此可以直接根据Volume Bitmap的情况，向快照中已删除的区块写入新的数据，而不用花时间去擦除原本的数据。 Linux启用Trim 确认 SSD 、操作系统、文件系统都支持 TRIM 12345678910111213141516# discard_granularity 非 0 表示支持[root@yadoom ~]# cat /sys/block/sda/queue/discard_granularity0[root@yadoom ~]# cat /sys/block/nvme0n1/queue/discard_granularity512# DISC-GRAN (discard granularity) 和 DISC-MAX (discard max bytes) 列非 0 表示该 SSD 支持 TRIM 功能。[root@yadoom ~]# lsblk --discardNAME DISC-ALN DISC-GRAN DISC-MAX DISC-ZEROsda 0 0B 0B 0├─sda1 0 0B 0B 0├─sda2 0 0B 0B 0└─sda3 0 0B 0B 0sr0 0 0B 0B 0nvme0n1 512 512B 2T 1nvme1n1 512 512B 2T 1 开启 123对于 ext4 文件系统，可以在/etc/fstab里添加 discard 参数来启用 TRIM，添加前请确认你的 SSD 支持 TRIM。[root@yadoom ~]# vim /etc/fstab/dev/sdb1 /data1 ext4 defaults,noatime,discard 0 0 Windows启用Trim 注意：如果SSD组RAID0后，将失去Trim功能。 RAID striping（条带化） 条带（strip）是把连续的数据分割成相同大小的数据块，把每段数据分别写入到阵列中的不同磁盘上的方法。简单的说，条带是一种将多个磁盘驱动器合并为一个卷的方法。 许多情况下，这是通过硬件控制器来完成的。 why striping? 首先介绍什么是磁盘冲突。当多个进程同时访问一个磁盘时，磁盘的访问次数（每秒的 I/O 操作，IOPS）和数据传输率（每秒传输的数据量，TPS）达到极限后，后面的进程就需要等待，这时就是所谓的磁盘冲突。 避免磁盘冲突是优化 I/O 性能的一个重要目标，而 I/O 性能的优化与其他资源（如CPU和内存）的优化有着很大的区别,I/O 优化最有效的手段是将 I/O 最大限度的进行平衡。 条带化技术就是一种自动的将 I/O 的负载均衡到多个物理磁盘上的技术，条带化技术就是将一块连续的数据分成很多小部分并把他们分别存储到不同磁盘上去。这就能使多个进程同时访问数据的多个不同部分而不会造成磁盘冲突，而且在需要对这种数据进行顺序访问的时候可以获得最大程度上的 I/O 并行能力，从而获得非常好的性能。 stripe width 条带宽度：是指同时可以并发读或写的条带数量。这个数量等于RAID中的物理硬盘数量。例如一个经过条带化的，具有4块物理硬盘的阵列的条带宽度就是 4。增加条带宽度，可以增加阵列的读写性能。道理很明显，增加更多的硬盘，也就增加了可以同时并发读或写的条带数量。 stripe depth(stripe unit) 条带深度：指的是条带的大小。这个参数指的是写在每块磁盘上的条带数据块的大小。RAID的数据块大小一般在2KB到512KB之间(或者更大)，其数值是 2 的次方，即2KB,4KB,8KB,16KB这样。 条带大小对性能的影响比条带宽度难以量化的多： 减小条带大小: 由于条带大小减小了，则文件被分成了更多个，更小的数据块。这些数据块会被分散到更多的硬盘上存储，因此提高了传输的性能，但是由于要多次寻找不同的数据块，磁盘定位的性能就下降了。 增加条带大小: 与减小条带大小相反，会降低传输性能，提高定位性能。 根据上边的论述，我们会发现根据不同的应用类型，不同的性能需求，不同驱动器的不同特点(如SSD硬盘)，不存在一个普遍适用的”最佳条带大小”。所以这也是存储厂家，文件系统编写者允许我们自己定义条带大小的原因。 stripe size 有时也称block size块大小、chunk size簇大小、stripe length条带长度、granularity粒度，是单块磁盘上的每次I/O的最小单位。 案例：Raid1+0 stripe size for MySQL InnoDB RAID卡 写策略 write-through和write-back write-through 数据在写入存储的同时，要写入缓存，这种方式安全但是会牺牲写性能，因为只有等数据完全落入硬盘后，才算是一次io完成，这个过程会造成cpu的iowait。 write-back 数据直接写入缓存，写缓存的速度是远远大于写磁盘的，所以这种方式可以提高服务器的写性能。也许你会想当断电了怎么办？不用担心，raid卡是有电池的，完全可以支持缓存中的数据再写入磁盘。除非点背，raid卡电池也没电了。 我们生产环境用的就是write-back，就是并且还设置了force write-back (即使电池没电了，也要写缓存)，这样有了点冒险，但是大幅度的提高了写性能，我觉得利大于弊吧。 读策略read policy No-Read-Ahead（非预读） Read-ahead（预读） 提前加载数据到缓存，加速顺序读请求。 Adaptive（自适应） 如果最近两次的磁盘访问都落在了连续的扇区内那就采用Read-ahead,否则就采用No-Read-ahead。 Disk cache Policy 磁盘上的缓存，区别于raid卡的缓存，该项SAS和SATA一般都是关的,因为掉电了有可能会丢数据，ssd可以打开。 Networking Profile查看网卡1234567891011121314151617181920212223242526272829[root@yadoom ~]# lspci | grep Ethernet01:00.0 Ethernet controller: Broadcom Corporation NetXtreme BCM5720 Gigabit Ethernet PCIe01:00.1 Ethernet controller: Broadcom Corporation NetXtreme BCM5720 Gigabit Ethernet PCIe02:00.0 Ethernet controller: Broadcom Corporation NetXtreme BCM5720 Gigabit Ethernet PCIe02:00.1 Ethernet controller: Broadcom Corporation NetXtreme BCM5720 Gigabit Ethernet PCIe# 示：四块博通千兆网卡[root@yadoom ~]# ethtool bond0Settings for bond0: Supported ports: [ ] Supported link modes: Not reported Supported pause frame use: No Supports auto-negotiation: No Advertised link modes: Not reported Advertised pause frame use: No Advertised auto-negotiation: No Speed: 1000Mb/s Duplex: Full # 当前工作在全双工模式 Port: Other PHYAD: 0 Transceiver: internal Auto-negotiation: off Link detected: yes[root@yadoom ~]# ip addr show bond06: bond0: &lt;BROADCAST,MULTICAST,MASTER,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP link/ether f8:bc:12:48:91:64 brd ff:ff:ff:ff:ff:ff inet6 fe80::fabc:12ff:fe48:9164/64 scope link valid_lft forever preferred_lft forever 主板1234567891011121314151617181920[root@yadoom ~]# dmidecode -t baseboard# dmidecode 2.11SMBIOS 2.7 present.Handle 0x0200, DMI type 2, 9 bytesBase Board Information Manufacturer: Dell Inc. Product Name: 0DCWD1 Version: A02 Serial Number: ..CN1374043800AE. Asset Tag: Not SpecifiedHandle 0x2900, DMI type 41, 11 bytesOnboard Device Reference Designation: Integrated NIC 1 Type: Ethernet Status: Enabled Type Instance: 1 Bus Address: 0000:01:00.0...... PCI设备PCI是CPU和外围设备通信的高速传输总线。 链接：PCI_Express GT/s 它是QPI(QuickPath Interconnect)的数据传输单位，类似于MHz相对于FSB。QPI是intel推出i7时所使用的数据总线。 FSB与QPI都是前端数据总线，区别是QPI的传输速率比FSB的传输速率快一倍。QPI总线采用的是2:1比率，意思就是实际的数据传输速率两倍于实际的总线时钟速率。所以6.4GT/s的总线速率其实际的总线时钟频率是 3.2GHz。 FSB的传输速率单位实际上是MT/s，通常我们所说的总线传输速率单位MHz是我们习惯上的称呼，是对时钟频率单位的挪用。 一开始的时候总线频率是与数据传输速率一致的，比如33MHz的总线的总线时钟频率是33MHz。但是后来从Pentium Pro开始，FSB采用”quad pumped”四倍并发技术做了改良。所谓quad pumped 就是说在每个总线时钟周期内传送四次数据，也就是说总线的数据传输速率等于总线时钟频率的4倍，如果是333MHz的时钟频率的总线那么其数据传输速率为1333MT/s（即是1.333GT/s），但是我们习惯上还是称为1333MHz。 GT/s，它明确地表明的是QPI总线实际的数据传输速率而不是时钟频率。 查看pci设备123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[root@yadoom ~]# lspci # pciutils软件包7f:08.0 System peripheral: Intel Corporation Xeon E5 v2/Core i7 QPI Link 0 (rev 04)......7f:0c.1 System peripheral: Intel Corporation Xeon E5 v2/Core i7 Unicast Registers (rev 04)......7f:16.2 System peripheral: Intel Corporation Xeon E5 v2/Core i7 Broadcast Registers (rev 04)[root@yadoom ~]# lspci -vt-+-[0000:7f]-+-08.0 Intel Corporation Xeon E5 v2/Core i7 QPI Link 0 | +-09.0 Intel Corporation Xeon E5 v2/Core i7 QPI Link 1...... | +-0f.0 Intel Corporation Xeon E5 v2/Core i7 Integrated Memory Controller 0 Target Address/Thermal Registers...... | +-10.7 Intel Corporation Xeon E5 v2/Core i7 Integrated Memory Controller 1 Channel 0-3 ERROR Registers 3 | +-13.0 Intel Corporation Xeon E5 v2/Core i7 R2PCIe | +-13.1 Intel Corporation Xeon E5 v2/Core i7 R2PCIe | +-13.4 Intel Corporation Xeon E5 v2/Core i7 QPI Ring Registers | +-13.5 Intel Corporation Xeon E5 v2/Core i7 QPI Ring Performance Ring Monitoring | +-16.0 Intel Corporation Xeon E5 v2/Core i7 System Address Decoder | +-16.1 Intel Corporation Xeon E5 v2/Core i7 Broadcast Registers | \-16.2 Intel Corporation Xeon E5 v2/Core i7 Broadcast Registers \-[0000:00]-+-00.0 Intel Corporation Xeon E5 v2/Core i7 DMI2 +-01.0-[02]--+-00.0 Broadcom Corporation NetXtreme BCM5720 Gigabit Ethernet PCIe | \-00.1 Broadcom Corporation NetXtreme BCM5720 Gigabit Ethernet PCIe +-01.1-[01]--+-00.0 Broadcom Corporation NetXtreme BCM5720 Gigabit Ethernet PCIe | \-00.1 Broadcom Corporation NetXtreme BCM5720 Gigabit Ethernet PCIe +-02.0-[04]-- +-02.2-[03]----00.0 LSI Logic / Symbios Logic MegaRAID SAS 2008 [Falcon] +-03.0-[05]-- +-03.2-[06]-- +-05.0 Intel Corporation Xeon E5 v2/Core i7 VTd/Memory Map/Misc +-05.2 Intel Corporation Xeon E5 v2/Core i7 IIO RAS +-11.0-[07]-- +-16.0 Intel Corporation C600/X79 series chipset MEI Controller #1 +-16.1 Intel Corporation C600/X79 series chipset MEI Controller #2 +-1a.0 Intel Corporation C600/X79 series chipset USB2 Enhanced Host Controller #2 +-1c.0-[08]-- +-1c.7-[09-0d]----00.0-[0a-0d]--+-00.0-[0b-0c]----00.0-[0c]----00.0 Matrox Electronics Systems Ltd. G200eR2 | \-01.0-[0d]-- +-1d.0 Intel Corporation C600/X79 series chipset USB2 Enhanced Host Controller #1 +-1e.0-[0e]-- +-1f.0 Intel Corporation C600/X79 series chipset LPC Controller \-1f.2 Intel Corporation C600/X79 series chipset 6-Port SATA AHCI Controller[root@yadoom ~]# lspci -xxx -s 7f:13.5 # x越多，列出的信息越详细7f:13.5 Performance counters: Intel Corporation Xeon E5 v2/Core i7 QPI Ring Performance Ring Monitoring (rev 04)00: 86 80 36 0e 00 00 00 00 04 00 01 11 10 00 80 00......[root@yadoom ~]# lspci -vv -s 7f:13.5 # v越多，列出的信息越详细7f:13.5 Performance counters: Intel Corporation Xeon E5 v2/Core i7 QPI Ring Performance Ring Monitoring (rev 04) Subsystem: Dell Device 048c Control: I/O- Mem- BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap- 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast &gt;TAbort- &lt;TAbort- &lt;MAbort- &gt;SERR- &lt;PERR- INTx- USB设备1234567891011121314151617[root@yadoom ~]# lsusb # usbutils包Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hubBus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hubBus 001 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching HubBus 002 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching HubBus 001 Device 003: ID 0624:0248 Avocent Corp. Virtual HubBus 001 Device 004: ID 0624:0249 Avocent Corp. Virtual Keyboard/Mouse[root@yadoom ~]# lsusb -vtBus# 2`-Dev# 1 Vendor 0x1d6b Product 0x0002 `-Dev# 2 Vendor 0x8087 Product 0x0024Bus# 1`-Dev# 1 Vendor 0x1d6b Product 0x0002 `-Dev# 2 Vendor 0x8087 Product 0x0024 `-Dev# 3 Vendor 0x0624 Product 0x0248 `-Dev# 4 Vendor 0x0624 Product 0x0249 查看内核产生的硬件日志 /var/log/dmesg 系统启动，一次性将启动时关于硬件的kernel日志写入该文件。 dmesg命名 实时记录kernel日志，譬如插入USB设备，可使用dmesg命令查看。 获取硬件命令汇总1234567891011121314151617181920212223242526271. CPU型号dmidecode -t 4| awk '/Version/ &amp;&amp; /CPU/'|uniq2. CPU核数grep -c 'processor' /proc/cpuinfosysctl kern.smp.cpus|awk '&#123;print $2&#125;'3.内存大小free -m|awk '/Mem/&#123;printf("%d\n", $2/1024+0.5)&#125;'sysctl hw.physmem|awk '&#123;printf ("%d\n", $2/1073741824+0.5)&#125;'4.硬盘总大小fdisk -l|awk '/Disk \/dev\//&#123;sum +=$3&#125;END&#123;printf("%d\n", sum+0.5)&#125;'sysctl kern.geom.conftxt|grep -Eo 'DISK \w+ \w+'|awk '&#123;sum +=$3&#125;END&#123;printf("%d\n", sum/1000000000+0.5)&#125;' df -Pm | awk '/^\/dev\//&#123;sum +=$2&#125;END&#123;printf("%d\n", sum/1024+0.5)&#125;'5.主板型号dmidecode -t 1| awk '/Product Name/'6.取主板Serialdmidecode -t 1|awk '/Serial/'一句话脚本：dmidecode -t 4| awk '/Version:/'|tail -n1if [ `uname` == Linux ];then grep -c 'processor' /proc/cpuinfo;else sysctl kern.smp.cpus|awk '&#123;print $2&#125;';fiif [ `uname` == Linux ];then free -m|awk '/Mem/&#123;printf("%d\n", $2/1000+0.5)&#125;';else sysctl hw.physmem|awk '&#123;printf ("%d\n", $2/1073741824+0.5)&#125;';fiif [ `uname` == Linux ];then fdisk -l|awk '/Disk \/dev\//&#123;sum +=$3&#125;END&#123;printf("%d\n", sum+0.5)&#125;';else sysctl kern.geom.conftxt|egrep -o 'DISK \w+ \w+'|awk '&#123;sum +=$3&#125;END&#123;printf("%d\n", sum/1000000000+0.5)&#125;';fidmidecode -t 1| awk '/Product Name/' System TuningStoargeStorage is very slow compare to memory. Linux has two way to compensate the issue. Caching Read from memory, write to memory Read can be cached, write can be deferred I/O Schedulers Kernel attempt to recorder, coalesce I/O requests（临近扇区，合并读请求） Minimize relocating magnetic head（最小化磁头的动作，重新定位） I/O TuningTuning Theory L: Queue length: average number of requests waiting in the system A: Arrival rate: the rate at which requests enter a system W: Wait time: average time to satisfy a request also known as wall clock,latency,response time, or residence time L = A * W Queue Length Requests are buffered in memory L may be read-write tunable or a read-only measurement Wait Time Includes Queue time（排队时间） Service time（服务时间） Tactics（策略） Reduce queue time Reduce service time L = A W = A (Tq + Ts) Service Time Includes Sysem time: time in kernel mode User time: time in user mode(doing useful work) Tactics Reduce system time(blocks user mode operations) spend as much time as needed in user mode L = A W = A (Q + S) = A * (Tq + (Tsys + Tuser)) Summary of Queue Theory L: Queue length A: Arrival rate(requests/second) W: Wait time(latency, time to satisfy a request) Q: Queue time S: Service time(includes system time, user time) C: Complete rate(requests/second) Steady state: A = C L = A W = A (Q + S) = A * (Tq + (Tsys + Tuser)) Summary of strategies Tune L Constrain queue length Sort the queue to prefer reads Tune A or C Reduce visit count by distributing across multiple resources(SMP,RAID) Defer resource visits until think time(lazy write) Improve throughput for resource(more efficient protocol, less overhead) Tune W Use expiration time for requests use resources with smaller service time(in-memory cache vs disk) I/O Scheduler参考：http://www.cnblogs.com/cobbliu/p/5389556.html cfq(Complete Fair Queuing) default schduler after kernel 2.6.18 它试图为竞争块设备使用权的所有进程分配一个请求队列和一个时间片，在调度器分配给进程的时间片内，进程可以将其读写请求发送给底层块设备，当进程的时间片消耗完，进程的请求队列将被挂起，等待调度。 每个进程的时间片和每个进程的队列长度取决于进程的IO优先级，每个进程都会有一个IO优先级，CFQ调度器将会将其作为考虑的因素之一，来确定该进程的请求队列何时可以获取块设备的使用权。IO优先级从高到低可以分为三大类:RT(real time),BE(best try),IDLE(idle),其中RT和BE又可以再划分为8个子优先级。 实际上，我们已经知道CFQ调度器的公平是针对于进程而言的，而只有同步请求(read或syn write)才是针对进程而存在的，他们会放入进程自身的请求队列，而所有同优先级的异步请求，无论来自于哪个进程，都会被放入公共的队列，异步请求的队列总共有8(RT)+8(BE)+1(IDLE)=17个。 IO Priority Class 1(real time): first-access to disk, can starve（饿死） other classes 0-7: The scheduling class data Class 2(best-effort): round-robin access, the default 0-7: The scheduling class data Class 3(idle): receives disk I/O only if no other requests in queue ionice命令可调节进程的IO优先级 1234ionice -n0 -c1 -p pidionice -n7 -c2 -p pidionice -c3 -p pid # 我不入地狱，谁入地狱ionice -c 2 -n 0 bash # Runs ’bash’ as a best-effort program with highest priority. deadline with predictable service time（可预见的服务时间） for virtualization host Deadline算法中引入了四个队列，这四个队列可以分为两类，每一类都由读和写两类队列组成，一类队列用来对请求按起始扇区序号进行排序，通过红黑树来组织，称为sort_list；另一类对请求按它们的生成时间进行排序，由链表来组织，称为fifo_list。每当确定了一个传输方向(读或写)，那么将会从相应的sort_list中将一批连续请求dispatch到requst_queue的请求队列里，具体的数目由fifo_batch来确定。只有下面三种情况才会导致一次批量传输的结束： 对应的sort_list中已经没有请求了 下一个请求的扇区不满足递增的要求 上一个请求已经是批量传输的最后一个请求了 所有的请求在生成时都会被赋上一个期限值(根据jiffies)，并按期限值排序在fifo_list中，读请求的期限时长默认为为500ms，写请求的期限时长默认为5s，可以看出内核对读请求是十分偏心的，其实不仅如此，在deadline调度器中，还定义了一个starved和writes_starved，writes_starved默认为2，可以理解为写请求的饥饿线，内核总是优先处理读请求，starved表明当前处理的读请求批数，只有starved超过了writes_starved后，才会去考虑写请求。因此，假如一个写请求的期限已经超过，该请求也不一定会被立刻响应，因为读请求的batch还没处理完，即使处理完，也必须等到starved超过writes_starved才有机会被响应。为什么内核会偏袒读请求？这是从整体性能上进行考虑的。读请求和应用程序的关系是同步的，因为应用程序要等待读取的内容完毕，才能进行下一步工作，因此读请求会阻塞进程，而写请求则不一样，应用程序发出写请求后，内存的内容何时写入块设备对程序的影响并不大，所以调度器会优先处理读请求。 默认情况下，读请求的超时时间是500ms，写请求的超时时间是5s。 这篇文章说在一些多线程应用下，Deadline算法比CFQ算法好。这篇文章说在一些数据库应用下，Deadline算法比CFQ算法好。 anticipatory(AS) wait for a while after read request for sequential read workloads（大量顺序读的） Anticipatory算法从Linux 2.6.33版本后，就被移除了，因为CFQ通过配置也能达到Anticipatory算法的效果。 noop(No Operation) quick to response, low CPU overhead for SSD,virtualization guests（宿主机使用了deadline，则虚拟机使用noop，因为真正写盘操作是主机完成） Noop调度算法也叫作电梯调度算法，它将IO请求放入到一个FIFO队列中，然后逐个执行这些IO请求，当然对于一些在磁盘上连续的IO请求，Noop算法会适当做一些合并。这个调度算法特别适合那些不希望调度器重新组织IO请求顺序的应用。 这种调度算法在以下场景中优势比较明显： 在IO调度器下方有更加智能的IO调度设备。如果您的Block Device Drivers是Raid，或者SAN，NAS等存储设备，这些设备会更好地组织IO请求，不用IO调度器去做额外的调度工作； 上层的应用程序比IO调度器更懂底层设备。或者说上层应用程序到达IO调度器的IO请求已经是它经过精心优化的，那么IO调度器就不需要画蛇添足，只需要按序执行上层传达下来的IO请求即可。 对于一些非旋转磁头氏的存储设备，使用Noop的效果更好。因为对于旋转磁头式的磁盘来说，IO调度器的请求重组要花费一定的CPU时间，但是对于SSD磁盘来说，这些重组IO请求的CPU时间可以节省下来，因为SSD提供了更智能的请求调度算法，不需要内核去画蛇添足。 I/O Scheduler Manage /sys/block/\&lt;device>/queue/scheduler 切换I/O调度算法。 12[root@yadoom ~]# cat /sys/block/sda/queue/scheduler noop anticipatory deadline [cfq] 每种调度算法的可调参数 12345# 该目录会根据不同Schduler而变化[root@yadoom ~]# cd /sys/block/sda/queue/iosched/[root@yadoom iosched]# lsback_seek_max fifo_expire_async group_idle low_latency slice_async slice_idleback_seek_penalty fifo_expire_sync group_isolation quantum slice_async_rq slice_sync CFQ 1234567891011/sys/block/&lt;device&gt;/queue/iosched/slice_idle 当一个进程的队列被分配到时间片却没有 IO 请求时，调度器在轮询至下一个队列之前的等待时间，以提升 IO 的局部性，对于 SSD 设备，可以将这个值设为 0。/sys/block/&lt;device&gt;/queue/iosched/quantum 一个进程的队列每次被处理 IO 请求的最大数量，默认为 4，RHEL6 为 8，增大这个值可以提升并行处理 IO 的性能，但可能会造成某些 IO 延迟问题。/sys/block/&lt;device&gt;/queue/iosched/slice_async_rq 一次处理写请求的最大数/sys/block/&lt;device&gt;/queue/iosched/low_latency 如果IO延迟的问题很严重，将这个值设为 1 Deadline 1234567891011/sys/block/&lt;device&gt;/queue/iosched/writes_starved 进行一个写操作之前，允许进行多少次读操作/sys/block/&lt;device&gt;/queue/iosched/read_expire 读请求的过期时间，默认为 5ms/sys/block/&lt;device&gt;/queue/iosched/write_expire 写请求的过期时间，默认为 500ms/sys/block/sda/queue/iosched/front_merges 是否进行前合并 Anticipatory 12345678/sys/block/&lt;device&gt;/queue/iosched/antic_expire 预测等待时长，默认为 6ms/sys/block/&lt;device&gt;/queue/iosched/&#123;write_expire,read_expire&#125; 读写请求的超时时长/sys/block/&lt;device&gt;/queue/iosched/&#123;write_batch_expire,read_batch_expire&#125; 读写的批量处理时长 Queue /sys/block/\&lt;device>/queue/nr_requests 磁盘请求队列长度（一次性交给磁盘的请求数量）。增大它会牺牲更多内存。 12[root@yadoom ~]# cat /sys/block/sda/queue/nr_requests 128 /sys/block/\&lt;device>/queue/read_ahead_kb 预先读数据块大小，对于大量的连续读业务，可以增大它。 Kernel ModuleModule commands lsmod 12345678910111213141516[root@yadoom ~]# lsmod Module Size Used bytcp_diag 1041 0 inet_diag 8735 1 tcp_diag # 表示该模块被tcp_diag依赖，使用次数为1ip6table_filter 2889 0 ip6_tables 18732 1 ip6table_filterebtable_nat 2009 0 ebtables 18135 1 ebtable_natipt_MASQUERADE 2466 3 iptable_nat 6158 1 nf_nat 22759 2 ipt_MASQUERADE,iptable_natnf_conntrack_ipv4 9506 4 iptable_nat,nf_natnf_defrag_ipv4 1483 1 nf_conntrack_ipv4xt_state 1492 1 nf_conntrack 79758 5 ipt_MASQUERADE,iptable_nat,nf_nat,nf_conntrack_ipv4,xt_stateipt_REJECT 2351 2 /lib/modules/\&lt;kernel-release>/kernel/ 内核模块所在目录。 modinfo [ modulename… ] 123456789101112[root@yadoom ~]# modinfo sx8filename: /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/block/sx8.koversion: 1.0description: Promise SATA SX8 block driverlicense: GPLauthor: Jeff Garziksrcversion: 4772099AB984FE59198263Ealias: pci:v0000105Ad00008002sv*sd*bc*sc*i*alias: pci:v0000105Ad00008000sv*sd*bc*sc*i*depends: vermagic: 2.6.32-431.el6.x86_64 SMP mod_unload modversions parm: max_queue:Maximum number of queued commands. (min==1, max==30, safe==1) (int) modprobe [ modulename… ] rmmod [ modulename… ] Modules parameters 查看某模块有哪些参数可调整 12345678[root@yadoom ~]# modinfo -p usb_storagequirks:supplemental list of device IDs and their quirksdelay_use:seconds to delay before using a new deviceswi_tru_install:TRU-Install mode (1=Full Logic (def), 2=Force CD-Rom, 3=Force Modem)option_zero_cd:ZeroCD mode (1=Force Modem (default), 2=Allow CD-Rom[root@yadoom ~]# modinfo -p sx8max_queue:Maximum number of queued commands. (min==1, max==30, safe==1) 自定义参数 1234[root@yadoom ~]# cat /etc/modprobe.d/my.conf options usb_storage delay_use=3options st buffer_kbs=128options sx8 max_queue=10 使用modprobe命令重新加载这些模块，自定义的参数就会生效 123[root@yadoom ~]# modprobe usb_storage[root@yadoom ~]# modprobe st[root@yadoom ~]# modprobe sx8 Check runtime module parameters /sys/module/\/parameters/ Automatically loading modules /etc/sysconfig/modules/my.modules Linux init脚本会执行以上目录下modules结尾的文件。 1modprobe usb_storage|st|sx8 Tuned Tune a system on the fly as needed Based on tuning profiles max power saving max disk performance self made profile allowed（允许自定义tune方案） profile can even has monitoring program to run（还支持运行监控程序） SysV service tuned ktune Can be used with crond to switch between profiles 0 7 * 1-5 /usr/bin/tuned-adm profile throughput-performance 0 20 * 1-5 /usr/bin/tuned-adm profile server-powersave Use Tuned1234567891011121314151617181920[root@cmdb-192-168-21-241 ~]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) [root@yadoom ~]# tuned-adm activeCurrent active profile: virtual-guest[root@yadoom ~]# tuned-adm listAvailable profiles:- balanced - General non-specialized tuned profile- desktop - Optimize for the desktop use-case- latency-performance - Optimize for deterministic performance at the cost of increased power consumption- network-latency - Optimize for deterministic performance at the cost of increased power consumption, focused on low latency network performance- network-throughput - Optimize for streaming network throughput, generally only necessary on older CPUs or 40G+ networks- powersave - Optimize for low power consumption- throughput-performance - Broadly applicable tuning that provides excellent performance across a variety of common server workloads- virtual-guest - Optimize for running inside a virtual guest- virtual-host - Optimize for running KVM guestsCurrent active profile: virtual-guest[root@yadoom ~]# tuned-adm profile powersave latency-performance 1234567891011121314[root@yadoom ~]# grep -vE '^#|^$' /usr/lib/tuned/latency-performance/tuned.conf [main]summary=Optimize for deterministic performance at the cost of increased power consumption[cpu]force_latency=1governor=performanceenergy_perf_bias=performancemin_perf_pct=100[sysctl]kernel.sched_min_granularity_ns=10000000vm.dirty_ratio=10vm.dirty_background_ratio=3vm.swappiness=10kernel.sched_migration_cost_ns=5000000 throughput-performance Custom Tuning Profiles123456789101112[root@yadoom ~]# cd /usr/lib/tuned/[root@yadoom ~]# mkdir test-performance[root@yadoom ~]# vim test-performance/tuned.conf[main]include=latency-performancesummary=Test profile that uses settings for latency-performance tuning profile[root@yadoom ~]# tuned-adm list......- test-performance - Test profile that uses settings for latency-performance tuning profile...... CPU TuningCPU模式 内核模式 Ring0，Core程序运行。 用户模式 Ring3，用户进程运行。该模式的进程无法直接操作硬件，通过系统调用，由内核程序翻译后调用。 扩展小知识: 完全虚拟化如何让虚拟机认为自己直接运行在主机上？ 答：引入了-1环（硬件虚拟化），使虚拟机管理程序运行在-1环，虚拟机操作系统就可以运行在Ring0。 CPU Scheduler FF SCHED_FIFO: 先进先出的实时进程 RR SCHED_RR: 循环的实时进程 TS SCHED_OTHER (SCHED_NORMAL): 调度算法为CFQ。普通的共享时间进程，用户态进程。 1234567[root@kvm-2 ~]# ps -e -o class,cmdCLS CMDTS /sbin/initTS [kthreadd]FF [migration/0]TS [ksoftirqd/0]FF [migration/0] Scheduler Priority Real-time process (SCHED_FIFO/SCHED_RR) real-time priority 1 (lowest priority) to 99 (higest priority)。 Conventional process static priority(SCHED_NORMAL) 100 (highest priority) to 139 (lowest priority)。nice值可动态调整该值。 Conventional process’s static priority = (120 + Nice value) By default, conventional process starts with nice value of 0 which equals static priority 120 123456789101112131415[root@kvm-2 ~]# ps -e -o class,rtprio,pri,nice,cmdCLS RTPRIO PRI NI CMDTS - 19 0 /sbin/init # RTPRIO 为"-"，说明该进程没有实时优先级TS - 19 0 [kthreadd] # PRI 为19，说明它静态优先级为 100+19+0=119FF 99 139 - [migration/0] # CLS是FF，说明它是实时优先级 99TS - 19 0 [ksoftirqd/0]......TS - 19 0 /sbin/rsyslogd -i /var/run/syslogd.pid -c 5TS - 19 0 irqbalance --pid=/var/run/irqbalance.pidTS - 19 0 rpcbindTS - 19 0 dbus-daemon --systemTS - 19 0 NetworkManager --pid-file=/var/run/NetworkManager/NetworkManager.pidTS - 19 0 /usr/sbin/modem-managerTS - 19 0 rpc.statdTS - 19 0 /usr/sbin/acpid # 大多数用户进程，优先级都为 119 dynamic priority 指内核监控长时间未运行的（TS类别）进程，临时调高它的优先级（nice值），避免进程饥饿。相反地，也会惩罚长时间占用cpu的进程。 dynamic priority = max (100, min ( static priority - bonus + 5, 139)) bonus is ranging from 0 to 10, which is set by scheduler depends on the past history of the process; more precisely, it is related to the average sleep time of the process. Scheduler Priority Changing Changing Real-time/Conventional process priority. 12345678#Real-time process $chrt 80 ps -e -o class,rtprio,pri,nice,cmd..FF 80 120 - ps -e -o class,rtprio,pri,nice,cmd# Conventional process$nice -n 10 ps -e -o class,rtprio,pri,nice,cmd...TS - 12 10 ps -e -o class,rtprio,pri,nice,cmd Interrupt and IRQ中断请求（IRQ）是用于服务的请求，在硬件层发出。可使用专用硬件线路或者跨硬件总线的信息数据包（消息信号中断，MSI ）发出中断。启用中断后，接收 IRQ 后会提示切换到中断上下文。 CPU绑定后，它仍然要服务于中断。应该将中断绑定至那些非隔离的CPU上，从而避免那些隔离的CPU处理中断程序； /proc/interrupts文件列出每个I/O 设备中每个 CPU 的中断数，每个 CPU 核处理的中断数，中断类型，以及用逗号分开的注册为接收中断的驱动程序列表。（详情请参考 proc(5) man page：man 5 proc） 123456789101112131415161718192021[root@yadoom ~]# cat /proc/interrupts CPU0 CPU1 0: 14678 0 IO-APIC-edge timer 1: 2 0 IO-APIC-edge i8042 4: 2 0 IO-APIC-edge 7: 0 0 IO-APIC-edge parport0 8: 1 0 IO-APIC-edge rtc0 9: 0 0 IO-APIC-fasteoi acpi 12: 4 0 IO-APIC-edge i8042 14: 45394223 0 IO-APIC-edge ata_piix 15: 0 0 IO-APIC-edge ata_piix 16: 56 16232636 IO-APIC-fasteoi i915, p2p1 18: 5333843 11365439 IO-APIC-fasteoi uhci_hcd:usb4 20: 2277759 0 IO-APIC-fasteoi ata_piix 21: 3 0 IO-APIC-fasteoi ehci_hcd:usb1, uhci_hcd:usb2 22: 0 0 IO-APIC-fasteoi uhci_hcd:usb3 23: 3813 6412 IO-APIC-fasteoi uhci_hcd:usb5, Intel ICH7......# APIC表示高级可编程中断控制器（Advanced Programmable Interrupt Controlle）# APIC是SMP体系的核心，通过APIC可以将中断分发到不同的CPU 来处理。# i915：Intel i915 集成显卡驱动 Soft Interrupt and Context Switch上下文切换（也称做进程切换或任务切换）是指 CPU 从一个进程或线程切换到另一个进程或线程。 CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态，从任务保存到再加载的过程就是一次上下文切换。 查看中断12mpstatdstat -c 将IRQ绑定CPU1234echo CPU_MASK &gt; /proc/irq/&lt;irq number&gt;/smp_affinity# 案例：将CPU中断绑定到CPU #0,#1上。echo 3 &gt; /proc/irq/&lt;irq number&gt;/smp_affinity 将IRQ绑定到某个CPU，那么最好在系统启动时，将那个CPU隔离起来，不被scheduler通常的调度。可以通过在Linux kernel中加入启动参数：isolcpus=cpu-list将CPU隔离起来。 IRQ Irqbalanceirqbalance用于优化中断分配，它会自动收集系统数据以分析使用模式，并依据系统负载状况将工作状态置于 Performance mode 或 Power-save mode。处于Performance mode 时，irqbalance 会将中断尽可能均匀地分发给各个 CPU core，以充分利用 CPU 多核，提升性能。 处于Power-save mode 时，irqbalance 会将中断集中分配给第一个 CPU，以保证其它空闲 CPU 的睡眠时间，降低能耗 但是在实时系统中会导致中断自动漂移，对性能造成不稳定因素，在高性能的场合建议关闭。 1/etc/init.d/irqbalance stop 查看上下文切换12sar -w # 查看上下文切换的平均次数，以及进程创建的平均值vmstat 1 3 # 每秒上下文切换次数 如何减少上下文切换既然上下文切换会导致额外的开销，因此减少上下文切换次数便可以提高多线程程序的运行效率。减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。 - 无锁并发编程。多线程竞争时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash取模分段，不同的线程处理不同段的数据 - CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁 - 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态 - 协程。在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换 CPU Iffinity（姻亲关系）当软中断和上下文切换过大时。 1234567891011121314151617tasksetmask 二进程 #CPU0x0000 0001 0001：node 00x0000 0003 0011：node 0和10x0000 0005 0101：node 0和20x0000 0007 0111：node 0-2[root@yadoom ~]# taskset -p mask pid101, 3# CPU[root@yadoom ~]# taskset -p 0x00000005 101绑定进程101，CPU 0-2#、7#taskset -p -c 0-2,7 101# 指定CPU启动进程taskset mask -- programtaskset -c 0,5,7-9 – myprogram CPU 子系统123456789101112131415161718192021[root@yadoom ~]# mkdir /cpusets[root@yadoom ~]# vim /etc/fstabcpuset /cpusets cpuset defaults 0 0[root@yadoom ~]# mount -a[root@yadoom ~]# ls /cpusets/cgroup.clone_children cgroup.sane_behavior cpuset.mem_exclusive cpuset.memory_pressure cpuset.memory_spread_slab cpuset.sched_relax_domain_level taskscgroup.event_control cpuset.cpu_exclusive cpuset.mem_hardwall cpuset.memory_pressure_enabled cpuset.mems notify_on_releasecgroup.procs cpuset.cpus cpuset.memory_migrate cpuset.memory_spread_page cpuset.sched_load_balance release_agent#[root@yadoom ~]# cat /cpusets/cpuset.cpus 0-3# 创建子域[root@yadoom ~]# mkdir /cpusets/domain1[root@yadoom ~]# ls /cpusets/domain1/......[root@yadoom ~]# echo 0-1 &gt;/cpusets/domain1/cpuset.cpus #将CPU #0,#1绑定进来[root@yadoom ~]# echo 0 &gt;/cpusets/domain1/cpuset.mems #将内存绑定进来[root@yadoom ~]# echo #pid /cpusets/domain1/tasks #将某个进程绑定进来，该进程只能在CPU 0-1上运行[root@yadoom ~]# ps -e -o psr,pid,cmd Memory TuningMemory Management An important thing for kernel to do Paping（分页） is the way to manage system memory Memory is organized into pages For x86, normal page size is 4KiB(4096 Bytes) Processes do not address physical memory directly, each process has a virtual address space 32-bit: 4GiB maximum memory a process can have 64-bit: 16EiB maximum memory a process can have Process can only see physical pages that have been mapped into its virtual address, so security enforced（进程间是隔离的） Virtual page must translate to physical page in order to access data. VSZ vs. RSS when process requests memory, only reserve virtual memory address, but does not actually map them to physical pages UNTIL they are used. Virtual memory used: VIRT, VSIZE, VSZ Physical memory used: RES, RSS Processes can share memory by mapping same physical pages to their private virtual address space, kernel takes control（进程可以共享同一片物理内存） VIRT vs RES vs SHR VIRT – Virtual Memory Size (KiB) The total amount of virtual memory used by the task. It includes all code, data and shared libraries plus pages that have been swapped out and pages that have been mapped but not used.（一个任务使用的虚拟内存的总量，包括 代码、数据、共享库加上已换出的页和已经被映射出去了但是还没被使用的页。 简单理解就是所有的虚拟内存中含有共享库、共享内存、堆、栈和所有已经申请的内存空间。） 1234567# 利用命令查看：vsz=data + code + shared lib$ ps -a -o pid,pmem,cmd,vsz,drs,trs PID %MEM CMD VSZ DRS TRS 3870 0.0 ps -a -o pid,pmem,cmd,vsz,d 148912 148822 8910906 0.0 screen -dr 129744 129744 016116 0.0 sudo -i 195524 195524 016117 0.3 -zsh 156876 156876 0 RES – Resident Memory Size (KiB) The non-swapped physical memory a task is using.（一个任务使用的不可交换的物理内存大小。是一个进程正在使用的内存空间（堆、栈）。） SHR – Shared Memory Size (KiB) The amount of shared memory available to a task, not all of which is typically resident. It simply reflects memory that could be potentially shared with other processes.（一个任务正在使用的共享内存大小，这个大小对该进程不是固定的，它只是简单的反应了可以被其他进程共享的内存大小。） Page Walk Virtual to Physical address translations are stored in page tables These page table are stored in memory Looking up these page tables is a processes called a Page Walk Every memory access requires a Page Walk Hardware assisted but it is still expensive Typically, takes 10-100 CPU clock cycles The obvious optimization is to cache the results 一次虚拟内存地址到物理内存地址查找（page walk）太慢，所以引入TLB来缓存。 TLB - Translation look-aside buffer The Translation Lookaside Buffer(TLB) is a small CPU cache of recently used virtual to physical address mappings. TLB is to speed up virtual to physical address translations CPU checks TLB first if TLB hit, return address if TLB miss, do a Page Walk and store translation in TLB Using TLB, increases performance by as much as 15% Look up takes 0.5-1 clock cycle TLB is typically implemented as CAM CAM(Content addressable memory，内容寻址存储器) TLB cache has to be flushed on every context switch 123456789101112131415161718192021[root@localhost ~]# x86info -cx86info v1.25. Dave Jones 2001-2009Feedback to &lt;davej@redhat.com&gt;.Found 40 CPUsMP Configuration Table Header MISSING!--------------------------------------------------------------------------CPU #1EFamily: 0 EModel: 4 Family: 6 Model: 79 Stepping: 1CPU Model: Unknown model. Processor name string: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHzType: 0 (Original OEM) Brand: 0 (Unsupported)Number of cores per physical package=16Number of logical processors per socket=32Number of logical processors per core=2APIC ID: 0x0 Package: 0 Core: 0 SMT ID 0Cache infoTLB info Data TLB: 4KB pages, 4-way associative, 64 entries # TLB 很小 64 byte prefetching.Found unknown cache descriptors: 63 76 b5 c3 ff Huge Page操作系统默认的内存是以4KB分页的，而虚拟地址和内存地址需要转换，而这个转换要查表，CPU为了加速这个查表过程会内建TLB(Translation Lookaside Buffer)。显然，如果虚拟页越小，表里的条目数也就越多，而TLB大小是有限的，条目数越多TLB的Cache Miss也就会越高，所以如果我们能启用大内存页就能间接降低TLB Cache Miss。 Huge Page在内存中必须是连续的地址，所以通常在系统开机时指定内核参数直接分配。 123456789[root@yadoom ~]# sysctl -w vm.nr_hugepages=128vm.nr_hugepages = 128[root@yadoom ~]# cat /proc/meminfo | grep HugeAnonHugePages: 77824 kBHugePages_Total: 128HugePages_Free: 128HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kB Transparent HugePages（透明大页） 什么是Transparent HugePages（透明大页）? 简单的讲，对于内存占用较大的程序，可以通过开启HugePage来提升系统性能。但这里会有个要求，就是在编写程序时，代码里需要显示的对HugePage进行支持。 而红帽企业版Linux为了减少程序开发的复杂性，并对HugePage进行支持，部署了Transparent HugePages。Transparent HugePages是一个使管理Huge Pages自动化的抽象层，实现方案为操作系统后台有一个叫做khugepaged的进程，它会一直扫描所有进程占用的内存，在可能的情况下会把4kPage交换为Huge Pages。 为什么Transparent HugePages（透明大页）对系统的性能会产生影响？ 在khugepaged进行扫描进程占用内存，并将4kPage交换为Huge Pages的这个过程中，对于操作的内存的各种分配活动都需要各种内存锁，直接影响程序的内存访问性能。并且，这个过程对于应用是透明的，在应用层面不可控制,对于专门为4k page优化的程序来说，可能会造成随机的性能下降现象。 怎么设置Transparent HugePages（透明大页）? 查看是否启用透明大页 123[root@yadoom ~]# cat /sys/kernel/mm/transparent_hugepage/enabled [always] madvise never使用命令查看时，如果输出结果为[always]表示透明大页启用了，[never]表示透明大页禁用。 2. 关闭透明大页 12echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag 启用透明大页 12echo always &gt; /sys/kernel/mm/transparent_hugepage/enabled echo always &gt; /sys/kernel/mm/transparent_hugepage/defrag 4. 设置开机关闭 12345[root@yadoom ~]# vim /etc/rc.localif test -f /sys/kernel/mm/redhat_transparent_hugepage/enabled; then echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag fi 问题：Transparent Huge Pages相关概念及对mysql的影响 Swap内存回收和swap的关系，我们可以提出以下几个问题： 什么时候会进行内存回收呢？ 哪些内存会可能被回收呢？ 回收的过程中什么时候会进行交换呢？ 具体怎么交换？ 123456789101112131415161718192021222324vm.swappiness=&#123;0..100&#125;：使用交换分区的倾向性, 默认60 overcommit_memory=2： 过量使用（0：启发式过量；1：总是过量；2：允许下述超出百分比） overcommit_ratio=50： 可用虚存：swap+RAM*ratio swap: 2G RAM: 8G 可用虚存：memory=2G+8G*50%=6G 充分使用物理内存： 1、swap跟RAM一样大； 2、overcommit_memory=2, overcommit_ratio=100：swappiness=0； memory: swap+ram 参考设置： 1、Batch compute（批处理计算）：&lt;= 4 * RAM 2、Database server：&lt;= 1G 3、Application server：&gt;= 0.5 * RAM默认值：[root@yadoom ~]# cat /proc/sys/vm/overcommit_memory 0[root@yadoom ~]# cat /proc/sys/vm/swappiness 60[root@yadoom ~]# cat /proc/sys/vm/overcommit_ratio 50 Swap Tuning123456[root@localhost ~]# vmstat 1 3procs -----------memory---------- ---swap-- ----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 260352448 34480 2212952 0 0 0 1 2 3 0 0 100 0 0 0 0 0 260352192 34480 2212956 0 0 0 0 124 177 0 0 100 0 0 0 0 0 260352192 34480 2212956 0 0 0 0 27 44 0 0 100 0 0 Memory swpd: the amount of virtual memory used. Swap si: Amount of memory swapped in from disk (/s). so: Amount of memory swapped to disk (/s). paging in and paging out frequently hurts performance. si and so are very important. 123456# 在每个磁盘上建立swap分区，并给与相同优先级[root@localhost ~]# vim /etc/fstab...../dev/sda1 swap swap pri=5 0 0/dev/sdb1 swap swap pri=5 0 0/dev/sdc1 swap swap pri=1 0 0 # 最慢的磁盘，swap最小的优先级 Buffer Cache and Page Cache Buffer cache(Slab cache) used to cache file system meta data(dentries and inodes).跟文件无关的东西的缓存。 Page cache used to cache file system block data(file content).跟文件相关的东西的缓存。 123456[root@localhost ~]# sysctl -a |grep vfs_cache_pressure # Buffer cachevm.vfs_cache_pressure = 100# 0: 不回收dentries和inodes;# 1-99: 倾向于不回收；# 100: 倾向性等于 page cache和swap cache；# 100+: 倾向于回收； Slab在linux内核中会有许多小对象，这些对象构造销毁十分频繁，比如inode，dentry。这么这些对象如果每次构建的时候就向内存要一个页，而其实际大小可能只有几个字节，这样就非常浪费，为了解决这个问题就引入了一种新的机制来处理在同一页框中如何分配小存储器区。这就是我们要讨论的slab层。在讲述slab前，我想先铺垫一下有关内存页的概念，我们都知道在linux中内存都是以页为单位来进行管理的(通常为4KB)，当内核需要内存就调用如：kmem_getpages这样的接口(底层调用__alloc_pages())。那么内核是如何管理页的分配的，这里linux使用了伙伴算法。slab也是向内核申请一个个页，然后再对这些页框做管理来达到分配小存储区的目的的。 What is slab A slab is a set of one or more contiguous pages of memory set aside by the slab allocator for an individual cache. This memory is further divided into equal segments the size of the object type that the cache is managing.(Slab是一种内存分配器，通过将内存划分不同大小的空间分配给对象使用来进行缓存管理，应用于内核对象的缓存。) 作用（提升cpu访问内存小对象的效率） Slab对小对象进行分配，不用为每个小对象分配一个页，节省了空间。 内核中一些小对象创建析构很频繁，Slab对这些小对象做缓存，可以重复利用一些相同的对象，减少内存分配次数。 Anonymous pages Anonymous pages can be another large consumer of data Are not accociated with a file, but instead contain Program data - arrays, heap allocations, etc Anonymous memory regions Dirty memory mapped process private pages IPC shared memory region pages Anonymous pages are eligible for swap(Swap分区可以将不活跃的页交换到硬盘中，交换之后页将被释放。) Anonymous pages = RSS - Shared Memory Page Status Free Page is available for immediate allocation. Inactive Clean Page content has been written to disk, or has not changed since being read from disk. Page is available for allocation. Inactive Dirty Page not in use, and page content has been modified but not written back to disk. Active Page is in use by a process Dirty Page因为硬盘的读写速度远赶不上内存的速度，系统就把读写比较频繁的数据事先放到内存中，以提高读写速度，这就叫高速缓存，linux是以页作为高速缓存的单位，当进程修改了高速缓存里的数据时，该页就被内核标记为脏页，内核将会在合适的时间把脏页的数据写到磁盘中去，以保持高速缓存中的数据和磁盘中的数据是一致的。 12345678910[root@yadoom ~]# sysctl -a | grep dirtyvm.dirty_background_ratio = 10vm.dirty_background_bytes = 0vm.dirty_ratio = 20vm.dirty_bytes = 0vm.dirty_writeback_centisecs = 500vm.dirty_expire_centisecs = 3000[root@yadoom ~]# sysctl -a | grep pdflushvm.nr_pdflush_threads = 0 vm.dirty_expire_centisecs 默认是3000（单位是1/100秒）。这个值表示page cache中的数据多久之后被标记为脏数据。只有标记为脏的数据在下一个周期到来时pdflush才会刷入到磁盘，这样就意味着用户写的数据在30秒之后才有可能被刷入磁盘，在这期间断电都是会丢数据的。 vm.dirty_writeback_centisecs 默认一般是500（单位是1/100秒）。这个参数表示5s的时间pdflush就会被唤起去刷新脏数据。建议用户使用默认值。 vm.dirty_background_ratio(default 10) 这个参数指定了当文件系统缓存脏页数量达到系统内存百分之多少时（如5%）就会触发pdflush/flush/kdmflush等后台回写进程运行，将一定缓存的脏页异步地刷入外存； vm.dirty_ratio(default 20) 这个参数则指定了当文件系统缓存脏页数量达到系统内存百分之多少时（如10%），系统不得不开始处理缓存脏页（因为此时脏页数量已经比较多，为了避免数据丢失需要将一定脏页刷入外存）；在此过程中很多应用进程可能会因为系统转而处理文件IO而阻塞。 之前一直错误的以为dirty_ratio的触发条件不可能达到，因为每次肯定会先达到vm.dirty_background_ratio的条件，后来才知道自己理解错了。确实是先达到vm.dirty_background_ratio的条件然后触发flush进程进行异步的回写操作，但是这一过程中应用进程仍然可以进行写操作，如果多个应用进程写入的量大于flush进程刷出的量那自然会达到vm.dirty_ratio这个参数所设定的坎，此时操作系统会转入同步地处理脏页的过程，阻塞应用进程。 vm.nr_pdflush_threads pdflush是linux系统后台运行的一个线程，这个进程负责把page cahce中的dirty状态的数据定期的输入磁盘。 /proc/sys/vm/nr_pdflush_threads查看当前系统运行pdflush数量。当一段时间（一般是1s）没有任何的pdflush处于工作状态，系统会remove一个pdflush线程。pdflush最大和最小的数量是有配置的，但这些配置一般很少修改。 drop_caches（干净页的回收，缓存清理） 12345678910[root@yadoom ~]# cat /proc/sys/vm/drop_caches0[root@yadoom ~]# sync #先将缓存写入磁盘[root@yadoom ~]# echo 1 /proc/sys/vm/drop_caches #释放所有页缓冲内存[root@yadoom ~]# echo 2 /proc/sys/vm/drop_caches #释放未使用的slab缓冲内存[root@yadoom ~]# echo 3 /proc/sys/vm/drop_caches #释放所有页缓冲和slab缓冲内存备注：slab缓存详解（一）http://blog.chinaunix.net/uid-27102327-id-3268687.htmlslab缓存详解（二）http://blog.chinaunix.net/uid-27102327-id-3268711.htmlhttp://blog.csdn.net/hs794502825/article/details/7981524 OOM Kill123456789101112[root@yadoom ~]# cat /proc/sys/vm/panic_on_oom # 0:on, 1:off0[root@yadoom ~]# echo 1 /proc/sys/vm/panic_on_oom # 关闭oom kill，不推荐注意：由调整的进程衍生的进程将继承该进程的 oom_score。例如：如果 sshd 进程不受 oom _killer 功能影响，所有由 SSH 会话产生的进程都将不受其影响。当内存耗尽时，系统使用oom kill杀死大oom_score（-16~15，2的平方）的进程。oom_score得分由oom_adj得来。减小oom-adj值，避免被系统杀死：[root@yadoom ~]# echo -17 &gt; /proc/$(pidof sshd)/oom_adj-17：避免oom_killer杀死自己-16~15：帮助计算oom_score16：预留的最低级别，一般对于缓存的进程才有可能设置成这个级别 有时free查看还有充足的内存，但还是会触发OOM，是因为该进程可能占用了特殊的内存地址空间。(‘Lower’ memory zone like DMA, DMA32) min_free_kbytes /proc/sys/vm/min_free_kbytes强制Linux VM最低保留多少空闲内存（Kbytes） 内存管理从三个层次管理内存，分别是node, zone ,page。64位的x86物理机内存从高地址到低地址分为: Normal DMA32 DMA 12345[root@yadoom ~]# grep Node /proc/zoneinfo Node 0, zone DMANode 0, zone DMA32Node 0, zone NormalNode 1, zone Normal 每个zone都有自己的min low high,如下，但是单位是page。 123456789101112131415161718192021222324252627282930313233343536[root@yadoom ~]# grep "Node 0, zone" -A10 /proc/zoneinfo Node 0, zone DMA pages free 3934 min 3 low 3 high 4 scanned 0 spanned 4095 present 3835 nr_free_pages 3934 nr_inactive_anon 0 nr_active_anon 0--Node 0, zone DMA32 pages free 571977 min 749 low 936 high 1123 scanned 0 spanned 1044480 present 756520 nr_free_pages 571977 nr_inactive_anon 0 nr_active_anon 0--Node 0, zone Normal pages free 4737209 min 9478 low 11847 high 14217 scanned 0 spanned 9699328 present 9566720 nr_free_pages 4737209 nr_inactive_anon 166 nr_active_anon 3973945 上面可知：low = 5/4 min、high = 3/2 min。 min 和 low的区别： min下的内存是保留给内核使用的；当到达min，会触发内存的direct reclaim low水位比min高一些，当内存可用量小于low的时候，会触发 kswapd reclaim。当kswapd慢慢的将内存 回收到high水位，就开始继续睡眠 /proc/sys/vm/extra_free_kbytes 123[root@yadoom ~]# sysctl -a | grep freevm.min_free_kbytes = 90112vm.extra_free_kbytes = 0 意义：low = min_free_kbytes*5/4 + extra_free_kbytes 总结 调整该内存的内核参数的时候！调大的风险远大于调小的风险，会导致频繁的触发内存回收！如果有人想将vm.min_free_kbytes 调大，千万要注意当前的Free，一旦超过Free内存，会立刻触发direct reclaim。 进程间通信（SysV IPC） Types of IPC Semaphores（信号量） Message queues（消息队列） Shared memory 12345678910111213141516171819202122232425262728293031323334[root@kvm-2 ~]# ipcs ------ Shared Memory Segments --------key shmid owner perms bytes nattch status 0x6c0006e7 0 zabbix 600 657056 6 ------ Semaphore Arrays --------key semid owner perms nsems 0x00000000 0 root 600 1 0x00000000 65537 root 600 1 0x7a0006e7 98306 zabbix 600 13 ------ Message Queues --------key msqid owner perms used-bytes messages [root@kvm-2 ~]# ipcs -l # IPC resource limits------ Shared Memory Limits --------max number of segments = 4096 # SHMMNImax seg size (kbytes) = 49291832 # SHMMAXmax total shared memory (kbytes) = 25165824 # SHMALLmin seg size (bytes) = 1------ Semaphore Limits --------max number of arrays = 128 # SEMMNImax semaphores per array = 250 # SEMMSLmax semaphores system wide = 32000 # SEMMNSmax ops per semop call = 100 # SEMOPMsemaphore max value = 32767------ Messages: Limits --------max queues system wide = 32768 # MSGMNImax size of message (bytes) = 65536 # MSGMAXdefault max size of queue (bytes) = 65536 # MSGMNB Tune Semaphores 1st, the maximum number of semaphores per semaphore array, default 250. 2st, the maximum number of semaphores allowed sysetm-wide, default 32000. 3st, the maximum number of semaphores of allowed operations per semaphore system call, default 32. 4st, the maximum number of semaphore arrays, default 128. so, 250 * 128 &lt;= 32000 12[root@kvm-2 ~]# sysctl -a | grep kernel.semkernel.sem = 250 32000 32 128 Tune Message Queues kernel.msgmnb The maximum number of bytes in a single message queue, default 65535. kernel.msgmni The maximum number of message queue, default ?. kernel.msgmax The maximum size of a message that can be passwd between processes, default 65535. 1234[root@kvm-2 ~]# sysctl -a | grep kernel.msgkernel.msgmax = 65536 # 限制进程可以发送消息的最大字节数kernel.msgmni = 32768 # 最大消息队列数kernel.msgmnb = 65536 # 一个消息队列中最大的字节数 Tune kernel.shmmni The maximum number of shared memory segments system-wide, default 4096. kernel.shmmax The maximum size of a shared memory segment that can be created, default 68719476736(64G). kernel.shmall The total amount of shared memory, in pages, that can be used at one time on the system. default 1234[root@yadoom ~]# sysctl -a | grep kernel.shmkernel.shmmax = 68719476736kernel.shmall = 4294967296 # 单位page，等于 4294967296(4g)*4096 bytekernel.shmmni = 4096 延展阅读 Linux内存中的Cache真的能被回收吗？ linux的内存回收和交换 File System TuningMount Options Barriers (barrier) 由于磁盘设备自带内部缓存，以便重新调整批量数据的写操作顺序，优化写入性能，因此文件系统必须在日志数据写入磁盘之后才能写commit记录，若commit 记录写入在先，而日志有可能损坏，那么就会影响数据完整性。Ext4默认启用barrier，只有当barrier之前的数据全部写入磁盘，才能写 barrier之后的数据。 Access Time (noatime) In most cases, however, atimeis not a large overhead due to the default relative atime (or relatime) behavior in the RHEL 6 kernel. The relatime behavior only updates atime if the previous atime is olderthan the modification time (mtime) or status change time (ctime). File System EXT4 内节点表初始化 对于超大文件系统，mkfs.ext4 进程要花很长时间初始化文件系统中到所有内节点表。可使用 -Elazy_itable_init=1 选项延迟这个进程。如果使用这个选项，内核进程将在挂载文件系统后继续初始化该文件它。可使用 mount 命令的 -o init_itable=n 选项控制发生初始化到比例，其中执行这个后台初始化的时间约为 1/n。n 的默认值为 10。 Auto-fsync 行为 因为在重命名、截取或者重新写入某个现有文件后，有些应用程序不总是可以正确执行 fsync()，在重命名和截取操作后，ext4 默认自动同步文件。这个行为与原有到 ext3 文件系统行为大致相同。但 fsync()操作可能会很耗时，因此如果不需要这个自动行为，请在 m ount 命令后使用 -o noauto_da_alloc 选项禁用它。这意味着该程序必须明确使用 fsync() 以保证数据一致。 日志 I/O 优先权 默认情况下，日志注释 I/O 比普通 I/O 的优先权稍高。这个优先权可使用 mount 命令的journal_ioprio=n 选项控制。默认值为 3。有效值范围为 0 -7，其中 0 时最高优先权 I /O。 XFS(large file system) Network TuningTune Network latency net.ipv4.tcp_low_latency optimizes for low latency optimizes for throughput(default) 默认的RHEL为高吞吐量设计。 TCP/UDP Total Maximum Buffers When receiving and network packets, there are buffers(queue length) Kernel adjusts the size of these buffers automatically System wide maximum buffers for TCP/UDP connections, usually no need to tune, set by kernel during boot, near the size of system memory net.ipv4.tcp_mem(pages) net.ipv4.udp_mem(pages) Each connection creates a buffer Tune UDP Socket Buffer Tune the minimum socket buffers for UDP connection net.ipv4.udp_rmem_min(bytes) net.ipv4.udp_wmem_min(bytes) Tune the default socket buffers for core networking, include udp connection net.core.rmem_default(bytes) net.core.wmem_default(bytes) Tune the maximum socket buffers for core networking, include udp connection net.core.rmem_max(bytes) net.core.wmem_max(bytes) 12345678910[root@localhost ~]# sysctl -a | grep net.ipv4.udpnet.ipv4.udp_mem = 24786432 33048576 49572864net.ipv4.udp_rmem_min = 4096net.ipv4.udp_wmem_min = 4096[root@localhost ~]# sysctl -a | grep net.core | grep memnet.core.wmem_max = 124928net.core.rmem_max = 124928net.core.wmem_default = 124928net.core.rmem_default = 124928# 由上可知 mem_default 等于 mem_max，表示已调节为最大吞吐量，缺点是需要占用大量内存。 Tune TCP Socket Buffer First, tune buffers of total networking(like UDP) net.core.rmem_max(bytes) net.core.wmem_max(bytes) Then tune buffers of TCP specific networking net.ipv4.tcp_rmem(bytes) net.ipv4.tcp_wmem(bytes) 12net.ipv4.tcp_wmem = 4096 16384 4194304net.ipv4.tcp_rmem = 4096 87380 4194304 min: minimum receive/send buffer for a tcp connection default: default buffer size, usually half of max buffer size max: maximum receive/send buffer for a tcp connection Total networking buffers &gt;= TCP buffers How much buffer to set? Set buffer too large will hurt network speed and latency for connections of small amounts data(HTTP/SSH) Set buffer too small will cause system dropping network packets To calculate buffer size for maximum throughput of a BDP(Bandwidth Delay Product，时延带宽积) connection.（时延带宽积代表发送的第一个比特即将达到终点时、发送端就已经发出了多少个比特。因此时延带宽积又称为以比特为单位的链路长度。） BDP = Bandwidth * Delay Example: 1 Mbits/s/8 * 2s = 262144 Bytes = 256 KiB when BDP goes above 64 KiB, tcp connections will use window scalling(滑动窗口) by default to enable full use of BDP buffer, good for sending large files over slow networks Ethernet Bonding Bonding mode balance-rr,0: provides fault tolerance and load balancing(more like app level compared to mode 4) active-backup,1: provides fault tolerance 802.3ad,4: Dynamic Link Aggregation, must configure switch also, default work on layer 2, can be set work on layer 2 and 3 with xmit_hash_policy=layer2+3 Bonding (Port Trunking) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@localhost network-scripts]# cat ifcfg-em1......DEVICE=em1MASTER=bond0SLAVE=yes[root@localhost network-scripts]# cat ifcfg-em2......DEVICE=em2MASTER=bond0SLAVE=yes[root@localhost network-scripts]# more ifcfg-bond0DEVICE=bond0TYPE=BondNAME=bond0BONDING_MASTER=yesBOOTPROTO=staticUSERCTL=noONBOOT=yesIPADDR=172.20.0.2PREFIX=24GATEWAY=172.20.0.1BONDING_OPTS="mode=1 miimon=100"# BONDING_OPTS="mode=802.3ad xmit_hash_policy=layer2+3"[root@localhost network-scripts]# cat /proc/net/bonding/bond0Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)Bonding Mode: fault-tolerance (active-backup)Primary Slave: NoneCurrently Active Slave: em1MII Status: upMII Polling Interval (ms): 100Up Delay (ms): 0Down Delay (ms): 0Slave Interface: em1MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: d0:94:66:24:77:f4Slave queue ID: 0Slave Interface: em2MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: d0:94:66:24:77:f6Slave queue ID: 0 Protocal Overheads When data is being sent over network, kernel forges packets, a typical TCP/IP packet head includes: Ethernet header, IP header and TCP header. TCP connection uses 52 bytes for protocol headers, with a default MTU of 1500 bytes, that’s (52/1500) = 3.5% overhead UDP connection with 28 bytes for protocol headers, that’s (28/1500) = 1.9% overhead Jumbo Frames To increase MTU can reduce these overhead MTU bigger that 1500 is called Jumbo Frames Every piece of networking equipment on the network must support Jumbo frames Nics, Switches, Routers, etc. Official maximum size of a Jumbo frame is 9000 bytes (52/ 9000) = 0.58% overhead, compared to 3.5% before 123[root@localhost network-scripts]# cat ifcfg-em1......MTU=9000 其他123tcp_max_tw_buckets: 只允许调大 tw：保存timewait的连接个数 established --&gt; tw txqueuelen 表示传送数据的缓冲区的最大长度。假设最大并发用户数为u，单次向用户推送数据占用的IP包为p个，则瞬间推送的IP包数为up，网卡发送队列长度需足够大以容纳这么多包数。考虑到一定的余量，建议txqueuelen设为u p 1.2，如果推送数据较小，则p = 1，txqueuelen = u 1.2。 12[root@yadoom ~]# ifconfig em1 | grep txqueuelen collisions:0 txqueuelen:1000 网卡接受发送队列 12345678910111213141516# 看网卡的接受发送队列长度，intel网卡缺省256，可以设置到 4096[root@yadoom ~]# ethtool -g em1Ring parameters for em1:Pre-set maximums:RX: 2047RX Mini: 0RX Jumbo: 0TX: 511 # 队列长度Current hardware settings:RX: 200RX Mini: 0RX Jumbo: 0TX: 511# 设置网卡的接受发送队列# ethtool -G em1 rx N 案例 Too much ARP cache? ip neighbor list 123net.ipv4.neigh.default.gc_thresh1 = 128net.ipv4.neigh.default.gc_thresh2 = 512net.ipv4.neigh.default.gc_thresh3 = 1024 ip neigh flush dev ethN 内核参数 net.ipv4.tcp_tw_recycle 不要在linux上启用net.ipv4.tcp_tw_recycle参数 cgroup Enable cgroup 123456789101112131415[root@localhost ~]# yum install gcc libcap-devel libcgroup-devel -y[root@localhost ~]# ls /etc/cgconfig.conf # cgroup主配置文件[root@localhost ~]# /etc/init.d/cgconfig startStarting cgconfig service: [ OK ][root@localhost ~]# [root@localhost ~]# ls -l /cgroup/total 0drwxr-xr-x 2 root root 0 Dec 6 01:06 blkiodrwxr-xr-x 2 root root 0 Dec 6 01:06 cpudrwxr-xr-x 2 root root 0 Dec 6 01:06 cpuacctdrwxr-xr-x 2 root root 0 Dec 6 01:06 cpusetdrwxr-xr-x 2 root root 0 Dec 6 01:06 devicesdrwxr-xr-x 2 root root 0 Dec 6 01:06 freezerdrwxr-xr-x 2 root root 0 Dec 6 01:06 memorydrwxr-xr-x 2 root root 0 Dec 6 01:06 net_cls Control cgroups Services cgconfig mount controllers create cgroups enables cgroup configure cgred assign process of specific users to cgroup assign specific processes to cgroup 123456789[root@localhost ~]# lssubsys -mcpuset /cgroup/cpusetcpu /cgroup/cpucpuacct /cgroup/cpuacctmemory /cgroup/memorydevices /cgroup/devicesfreezer /cgroup/freezernet_cls /cgroup/net_clsblkio /cgroup/blkio To Control CPU Usage（案例，CPU使用控制）1. Create cgroups under cpu controller 123456789101112131415161718192021222324[root@localhost ~]# vim /etc/cgconfig.d/mycpu.confgroup lesscpu &#123; cpu &#123; &#125;&#125;group morecpu &#123; cpu &#123; &#125;&#125;[root@localhost cgconfig.d]# /etc/init.d/cgconfig reloadStopping cgconfig service: [ OK ]Starting cgconfig service: [ OK ][root@localhost cgconfig.d]# ls /cgroup/cpu/lesscpu/cgroup.event_control cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_releasecgroup.procs cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat tasks[root@localhost cgconfig.d]# ls /cgroup/cpu/morecpu/cgroup.event_control cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_releasecgroup.procs cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat tasks# 临时调整[root@localhost cgconfig.d]# cgcreate -g cpu:/lesscpu[root@localhost cgconfig.d]# cgcreate -g cpu:/morecpu或者[root@localhost cgconfig.d]# mkdir /cgroup/cpu/&#123;less,more&#125; 2. Configure priorities or limits 123456789101112131415161718[root@localhost ~]# vim /etc/cgconfig.d/mycpu.confgroup lesscpu &#123; cpu &#123; cpu.shares=100; &#125;&#125;group morecpu &#123; cpu &#123; cpu.shares=200; &#125; [root@localhost cgconfig.d]# more /cgroup/cpu/lesscpu/cpu.shares 100[root@localhost cgconfig.d]# more /cgroup/cpu/morecpu/cpu.shares 200# 临时调整，重载后失效[root@localhost cgconfig.d]# cgset -r cpu.shares=100 lesscpu[root@localhost cgconfig.d]# cgset -r cpu.shares=200 morecpu 3. Assign processes to cgroups 12345678# 需要把其他CPU下线，只剩一核的情况下测试[root@localhost cgconfig.d]# cgexec -g cpu:lesscpu time dd if=/dev/zero of=/dev/null bs=1M count=200000200000+0 records in200000+0 records out209715200000 bytes (210 GB) copied, 11.4672 s, 18.3 GB/s0.01user 11.43system 0:11.46elapsed 99%CPU (0avgtext+0avgdata 1848maxresident)k0inputs+0outputs (0major+491minor)pagefaults 0swaps[root@localhost cgconfig.d]# cgexec -g cpu:morecpu time dd if=/dev/zero of=/dev/null bs=1M count=200000 To Control Memory Usage12345678910111213141516171819[root@localhost ~]# vim /etc/cgconfig.d/mymem.confgroup poormem &#123; memory &#123; # Physical memory limit, 256M, must be first set memory.limit_in_bytes=268435456; # Total memory limit, 512M, Physical Memory + Swap memory.memsw.limit_in_bytes=536870912; &#125;&#125;[root@localhost cgconfig.d]# /etc/init.d/cgconfig reload Stopping cgconfig service: [ OK ]Starting cgconfig service: [ OK ][root@localhost cgconfig.d]# cat /cgroup/memory/poormem/memory.limit_in_bytes 268435456[root@localhost cgconfig.d]# cat /cgroup/memory/poormem/memory.memsw.limit_in_bytes 268435456[root@localhost cgconfig.d]# cgexec -g memory:poormem dd if=/dev/zero of=/dev/null bs=1M count=300# 该命令会占用256M物理内存，以及300-256=44M Swap内存。 To Control Disk I/O Usage Create cgroup under blkio controller Configure blkio priorities and usage limit Assign processes to cgroups 12345678910111213141516171819202122232425262728293031323334[root@localhost ~]# vim /etc/cgconfig.d/myio.confgroup lowio &#123; blkio &#123; blkio.weight=100; # blkio.weight works under cfq scheduler &#125;&#125;group highio &#123; blkio &#123; blkio.weight=200; # blkio.weight works under cfq scheduler &#125;&#125;group ddio &#123; blkio &#123; blkio.throttle.read_bps_device="8:0 1000000" # 针对主号，从号“8:0”的磁盘设备限制I/O吞吐量 &#125;&#125;# 上面“8:0”（主号，从号）由下面的命令查看而来。[root@localhost ~]# ls -l /dev/sdabrw-rw---- 1 root disk 8, 0 Dec 6 03:25 /dev/sda[root@localhost cgconfig.d]# /etc/init.d/cgconfig reload Stopping cgconfig service: [ OK ]Starting cgconfig service: [ OK ][root@localhost ~]# cat /sys/block/sda/queue/scheduler noop anticipatory deadline [cfq][root@localhost ~]# echo 3 &gt; /proc/sys/vm/drop_caches [root@localhost ~]# [root@localhost ~]# ls -lh /tmp/bigfile* -rw-r--r-- 1 root root 1000M Dec 6 03:52 /tmp/bigfile1-rw-r--r-- 1 root root 1000M Dec 6 03:52 /tmp/bigfile2[root@localhost tmp]# cgexec -g blkio:lowio time cat ./bigfile1 &gt; /dev/null[root@localhost tmp]# cgexec -g blkio:highio time cat ./bigfile2 &gt; /dev/null Using cgred12345[root@localhost ~]# vim /etc/cgrules.conf #&lt;user&gt; &lt;controllers&gt; &lt;destination&gt;john:* blkio ddio/*:dd blkio ddio/[root@localhost ~]# /etc/init.d/cgred reload To Freeze Certain Processes123456789[root@localhost ~]# vim /etc/cgconfig.d/freeze.confgroup stopit &#123; freezer &#123; &#125;&#125;[root@localhost ~]# /etc/init.d/cgconfig reload[root@localhost ~]# echo #pid &gt; /cgroup/freezer/stopit/tasks # 绑定进程和freezer控制器[root@localhost ~]# echo FROZEN &gt; /cgroup/freezer/stopit/freezer.state # 冻结该进程[root@localhost ~]# echo THAWED &gt; /cgroup/freezer/stopit/freezer.state # 解冻 Commandstrace &amp; ltrace strace: kernerl space(system call) 123456789101112131415161718192021222324252627282930313233343536373839404142[root@localhost ~]# strace -e trace=network ping -c 1 127.0.0.1 socket(PF_INET, SOCK_RAW, IPPROTO_ICMP) = 3socket(PF_INET, SOCK_DGRAM, IPPROTO_IP) = 4connect(4, &#123;sa_family=AF_INET, sin_port=htons(1025), sin_addr=inet_addr("127.0.0.1")&#125;, 16) = 0getsockname(4, &#123;sa_family=AF_INET, sin_port=htons(55365), sin_addr=inet_addr("127.0.0.1")&#125;, [16]) = 0setsockopt(3, SOL_RAW, ICMP_FILTER, ~(ICMP_ECHOREPLY|ICMP_DEST_UNREACH|ICMP_SOURCE_QUENCH|ICMP_REDIRECT|ICMP_TIME_EXCEEDED|ICMP_PARAMETERPROB), 4) = 0setsockopt(3, SOL_IP, IP_RECVERR, [1], 4) = 0setsockopt(3, SOL_SOCKET, SO_SNDBUF, [324], 4) = 0setsockopt(3, SOL_SOCKET, SO_RCVBUF, [65536], 4) = 0getsockopt(3, SOL_SOCKET, SO_RCVBUF, [131072], [4]) = 0PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.setsockopt(3, SOL_SOCKET, SO_TIMESTAMP, [1], 4) = 0setsockopt(3, SOL_SOCKET, SO_SNDTIMEO, "\1\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0", 16) = 0setsockopt(3, SOL_SOCKET, SO_RCVTIMEO, "\1\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0", 16) = 0sendmsg(3, &#123;msg_name(16)=&#123;sa_family=AF_INET, sin_port=htons(0), sin_addr=inet_addr("127.0.0.1")&#125;, msg_iov(1)=[&#123;"\10\0\224B+\23\0\1\31&lt;\10\\\0\0\0\0V&gt;\2\0\0\0\0\0\20\21\22\23\24\25\26\27"..., 64&#125;], msg_controllen=0, msg_flags=0&#125;, 0) = 64recvmsg(3, &#123;msg_name(16)=&#123;sa_family=AF_INET, sin_port=htons(0), sin_addr=inet_addr("127.0.0.1")&#125;, msg_iov(1)=[&#123;"E\0\0TQ\253\0\0@\1*\374\177\0\0\1\177\0\0\1\0\0\234B+\23\0\1\31&lt;\10\\"..., 192&#125;], msg_controllen=32, &#123;cmsg_len=32, cmsg_level=SOL_SOCKET, cmsg_type=0x1d /* SCM_??? */, ...&#125;, msg_flags=0&#125;, 0) = 8464 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.035 ms--- 127.0.0.1 ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 0.035/0.035/0.035/0.000 ms+++ exited with 0 +++[root@localhost ~]# strace -e trace=file ls /execve("/bin/ls", ["ls", "/"], [/* 21 vars */]) = 0access("/etc/ld.so.preload", R_OK) = -1 ENOENT (No such file or directory)open("/etc/ld.so.cache", O_RDONLY) = 3open("/lib64/libselinux.so.1", O_RDONLY) = 3open("/lib64/librt.so.1", O_RDONLY) = 3open("/lib64/libcap.so.2", O_RDONLY) = 3open("/lib64/libacl.so.1", O_RDONLY) = 3open("/lib64/libc.so.6", O_RDONLY) = 3open("/lib64/libdl.so.2", O_RDONLY) = 3open("/lib64/libpthread.so.0", O_RDONLY) = 3open("/lib64/libattr.so.1", O_RDONLY) = 3statfs("/selinux", &#123;f_type="EXT2_SUPER_MAGIC", f_bsize=4096, f_blocks=1297385108, f_bfree=1296583382, f_bavail=1230678333, f_files=329531392, f_ffree=329482788, f_fsid=&#123;-525262460, 379377246&#125;, f_namelen=255, f_frsize=4096&#125;) = 0open("/proc/filesystems", O_RDONLY) = 3open("/usr/lib/locale/locale-archive", O_RDONLY) = 3stat("/", &#123;st_mode=S_IFDIR|0555, st_size=4096, ...&#125;) = 0open("/", O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 3bin boot cgroup dev etc home lib lib64 lost+found media mnt opt proc root sbin selinux srv sys tmp usr var+++ exited with 0 +++ ltrace: user space(library function call) 1234567891011121314151617181920212223242526272829303132333435363738[root@localhost ~]# ltrace date(0, 0, 0, 0x7f6770d11bc8, 88) = 0x30b3a22160__libc_start_main(0x401ec0, 1, 0x7ffff9ae0dc8, 0x408f30, 0x408f20 &lt;unfinished ...&gt;strrchr("date", '/') = NULLsetlocale(6, "") = "en_US.UTF-8"bindtextdomain("coreutils", "/usr/share/locale") = "/usr/share/locale"textdomain("coreutils") = "coreutils"__cxa_atexit(0x4057a0, 0, 0, 0x736c6974756572, 0x30b3f8e188) = 0getopt_long(1, 0x7ffff9ae0dc8, "d:f:I::r:Rs:u", 0x60c1a0, NULL) = -1nl_langinfo(131180, 0x7ffff9ae0dc8, 0x30b3f8e9ec, 0x30b3f8e9e4, 0) = 0x7f676affd425clock_gettime(0, 0x7ffff9ae0c90, 0x1a06440, 0x30b3f8e9e4, 0) = 0localtime(0x7ffff9ae0b80) = 0x30b3f93440strftime("", 140082153508067, NULL, 0x7ffff9ae0b23) = 4fwrite("Wed", 3, 1, 0x30b3f8f040) = 1fputc(' ', 0x30b3f8f040) = 32strftime("", 140082153508184, NULL, 0x7ffff9ae0b23) = 4fwrite("Dec", 3, 1, 0x30b3f8f040) = 1fputc(' ', 0x30b3f8f040) = 32fputc(' ', 0x30b3f8f040) = 32fwrite("5", 1, 1, 0x30b3f8f040) = 1fputc(' ', 0x30b3f8f040) = 32fwrite("21", 2, 1, 0x30b3f8f040) = 1fputc(':', 0x30b3f8f040) = 58fwrite("25", 2, 1, 0x30b3f8f040) = 1fputc(':', 0x30b3f8f040) = 58fwrite("49", 2, 1, 0x30b3f8f040) = 1fputc(' ', 0x30b3f8f040) = 32strlen("CST") = 3fwrite("CST", 3, 1, 0x30b3f8f040) = 1fputc(' ', 0x30b3f8f040) = 32fwrite("2018", 4, 1, 0x30b3f8f040) = 1exit(0 &lt;unfinished ...&gt;__fpending(0x30b3f8f040, 0, 0x30b3f8fbd0, 0x30b3f8fbd0, 4) = 29fclose(0x30b3f8f040) = 0Wed Dec 5 21:25:49 CST 2018__fpending(0x30b3f8f120, 0, 0x30b3f906b0, 0, 0x7f6770d10700) = 0fclose(0x30b3f8f120) = 0+++ exited (status 0) +++ systemtapPowerful tracing system to profile kernel space and user space code. 结尾 性能观测工具 性能测评工具 性能调优工具 sar命令 Linux Performance大全 附录http://honglus.blogspot.com/]]></content>
      <categories>
        <category>非原创</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tuning</tag>
        <tag>调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Overview of Performance Tuning]]></title>
    <url>%2F2018%2F11%2F06%2Flinux%2Fperformance-tuning%2Foverview-of-performance-tuning%2F</url>
    <content type="text"><![CDATA[前言为了更能通俗易懂的理解我们即将要的性能调优的话题，我在这里简单的和大家说一下我写这篇文章的写作方法 “5w+1h”方法。 5w+1h 就是对所做工作进行科学的分析，对某一工作在调查研究的基础上，就其工作内容（What）、责任者（Who）、工作岗位（Where）、工作时间（When）、怎样操作（How）以及为何这样做（Why），即”5W”、”1H”进行书面描述，并按此描述进行操作，达到完成职务任务的目标。 什么是性能调优？(what) 在说什么是性能调优之前我们先来说一下，计算机的体系结构。如上图，简单来说包括三块：硬件、操作系统、应用程序。其实，性能调优就是调节这些内容，包括硬件、操作系统、应用程序。 其中，这三大方面中又包含了若干的内容。硬件包括CPU、内存、磁盘、网卡等，操作系统包括进程、虚拟内存、文件系统、网络等，应用程序常见的有Apache、MySQL、Nginx、Memcahed等。 那什么是性能调优呢？性能调优就是对计算机硬件、操作系统和应用有相当深入的了解，调节三者之间的关系，实现整个系统（包括硬件、操作系统、应用）的性能最大化，并能不断的满足现有的业务需求。 为什么需要性能调优？(why)当一个发行版打包发送到客户手中的时候，它是为了完全兼容市场中大部分计算机而设计的。这是一个相当混杂的硬件集合（硬盘，显卡，网卡，等等）。所以Red Hat， SUSE，Mandriva，Ubuntu 和其他的一些发行版厂商选择了一些通用的设置来确保安装成功。 什么时候需要性能调优？(when) 上线前（基本优化） 包括操作系统优化和应用环境优化等，我称上线前的优化为基本优化也称为经验优化。根据你做过的项目和你工作中的经验对上线前的服务器或架构进行基本的性能优化来满足业务需求。 上线后（持续优化） 对上线后的项目进行性能监控包括服务器性能监控和服务性能监控，其中服务器性能监控包括CPU使用率、CPU负载、内存使用率、磁盘I/O、磁盘空间使用率、网络流量、系统进程等，服务性能监控包括apache、nginx、mysql等架构中所有的服务都需要进行性能监控，一但发现有问题我们都得去进行性能优化，在这个过程中我称为持续优化也称为监控优化。 什么地方需要性能调优？(where) 硬件 （CPU、内存、磁盘、网卡） 操作系统（进程、文件系统、内核） 应用程序（Nginx、MySQL） 什么人来进行性能调优？(who)一说起性能优化我们第一个想到的是运维工程师，他们来进行优化。其实我想说，这么说是片面的性能优化不仅仅是运维工程师的事。其实呢，性能优化是一个团队的事。我为什么这么说呢？下面我们想一下公司要做一个项目，那项目的具体流程是什么呢？可能不是很详细，但大体过程是样的： 运营提出需求 产品整理需求 开发开发具体的业务应用 运维搭建开发环境 QA 进行项目测试 运维进行项目上线 监控进行项目监控 …… 需要运营部、产品部、开发部、运维部、QA （测试）、监控等所有部门的参加，同样的一个项目（业务）存在性能问题，不会只是运维部门需要性能调优而是所以部门一起解决这个性能问题，这是缺一不可的。可能出现在产品，也可能出现在程序上，也可能是业务需要本身就有问题，也可能是运维的环境搭建有问题。但参加性能调优的更多的是开发、运维、测试和监控。 怎么样进行性能调优？(How)说一说怎么进行性能调优，具体步骤如下： 性能指标 –&gt; 确认衡量标准 性能测试 –&gt; 验证性能指标 性能分析 –&gt; 找出性能瓶颈 性能调优 –&gt; 解决性能问题 性能监控 –&gt; 检验调优效果 总结在这篇“性能优化概述”的博文中我只是给大家讲解一下具体的优化思路，帮助大家理解性能优化，这样大家更容易理解一些，让大家知道性能优化并不是传说中的那么难，难到不可动手去做，只要我们掌握好方法，什么难题都可以解决。]]></content>
      <categories>
        <category>非原创</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tuning</tag>
        <tag>调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[葡萄酒]]></title>
    <url>%2F2018%2F09%2F07%2Flife%2F%E8%91%A1%E8%90%84%E9%85%92%2F</url>
    <content type="text"><![CDATA[风土酒商类型 chateau庄园，除了勃艮第地区和香槟地区，大多数的酿酒商都以chateau作为生产单位。（特别一提，chateau和城堡无关，波美侯地区很多“车库酒庄”也标示为chateau） domaine勃艮第地区很特殊，因为拿破仑继承法的原因，那里的葡萄园都像是马赛克拼图一样分属于不同的主人，有时候一小片葡萄园有二三十个主人分别酿酒。这个时候只能采用domaine，其地位本身和chateu没有任何差别，只不过是由于法律问题而已。 maison不太常见，是指家酿葡萄酒，在香槟区很多，主要是和采购葡萄进行酿造的工厂区分开，指的是自家种的葡萄自家酿。（也不一定是品质非常好了，Krug和香槟王都不是家酿） 著名产区产区百科 Tom Stevenson 的索斯比酒水大百科《The Sotheby’s Wine Encyclopedia》 法国 波尔多 勃艮第 意大利 美国澳洲新西兰葡萄品种https://www.winesou.com/baike/grape/ 白品种雷司令（Riesling）陈年指数：可以很高。风情标识：白花，柑橘类水果等香气较为常见，有时还呈现出矿石气息甚至汽油味，可以绝干可以非常甜美，不变的是极高的酸度。身材：通常很瘦，甜型风格时会变得丰满。但极高的酸度让她无论如何不会显得臃肿，可谓天生丽质。口感：拥有高酸的特点以及中等酒体，法国出产的雷司令酒精度偏低，法国和新世纪出产的雷司令酒精度一般属于中等水平。著名产区：法国阿尔萨斯、澳大利亚嘉拉谷和伊顿谷、德国摩泽尔和莱茵高。 霞多丽（Chardonnay）成大器指数：高陈年指数：难说风情标识：霞多丽会根据季节和气候的变化而展现出不一样的风格口味，所以在某些地区表现出来的是桃子，柑橘以及柠檬的香味儿，在纬度偏低的地方可以吃出一种热带水果的风味。但通常印象是核果类、黄油、香草、烤面包身材：肥的特别肥，瘦的特别瘦。口感：使用凉爽地区出产的霞多丽酿造的葡萄酒拥有高酸度、中等酒体、中等酒精度的特点；而产自温暖地区的霞多丽酿造的葡萄酒则有着中-中低酸度、中高酒精度和酒体丰满的特点。著名产区：南澳、美国加州、新西兰、法国勃艮第、法国夏布利斯以及法国香槟。 长相思（Sauvignon Blanc）成大器指数：一般较低陈年指数：一般较低风情标识：百香果、青草、芦笋、菠萝身材：可肥可瘦、酸度不会差鹅娘一句话点评：「直入主题」有时有种难能的真诚性和高贵性。是绿茶婊的反面呢。口感：泼辣的植物类芳香和明艳的果香。产于凉爽地区的长相思酿造的葡萄酒有高酸的特点，通常是中低酒体；而使用温暖地区的长相思酿造的葡萄酒则是中低-中酒体，和前者一样，也是高酸哟！著名产地：新西兰马尔堡、法国波尔多、法国普伊芙美以及法国桑赛尔。 白皮诺成大器指数：低陈年指数：低风情标识：苹果，白桃，杏仁，香料身材：通常很瘦，偶尔肥一下让人害怕。 红品种黑皮诺陈年指数：较高，取决于自身质量。风情标识：果香红色水果为主，但风格变化较大，从泥土、蘑菇、皮革，到甜香料都有可能。身材：通常很瘦，也有微胖的时候。口感：使用黑皮诺酿造的葡萄酒拥有中低单宁、中高酸的特点，一般为中-中低酒体。 著名产区： Bourgogne法国勃艮第Cote de Nuits夜丘:几乎包含了全部的红葡萄酒特级田。Cote de Beaune伯恩丘:以白葡萄酒为主，但仍出产质量上乘的红酒。 American美国Oregon俄勒冈 ：相比勃艮第果实更加成熟，用桶更重，整体结构优雅且有不俗的复杂度。California Sonoma 加州索诺玛郡:Russian River Valley是这里生产黑皮诺的经典产区，相比俄勒冈更加成熟，果味偏向如黑樱桃等黑色水果，香草的风味也更加明显。 New Zealand新西兰Martinborough马丁堡：位于新西兰北岛，生产黑皮诺的精品产区，有新西兰的勃艮第之称。Central Otago中奥塔哥:大陆性气候的中奥塔哥相对炎热，成熟度高，黑樱桃果味和浓郁的浆果风格明显。 颜色深浅按酒体重轻排序 西拉成大器指数：高陈年指数：高风情标识：紫罗兰、黑色浆果、黑胡椒，过桶之后还有甜香料和木香。身材：可以很适中，也可以丰满。但和赤霞珠小姐一样，都属于有肉但不松软的类型。口感：希拉拥有中高单宁、中等酸度、高酒精的特点，一般是重酒体。著名产区：澳大利亚和法国北隆河。 赤霞珠（Cabernet Sauvignon）是用品丽珠和长相思两种不同品种的葡萄杂交培育而成的，赤霞珠葡萄的每颗果粒都比较小，而且果皮又厚颜色深，对于世界各地喜欢酿制葡萄酒的朋友都非常喜爱这种葡萄，在美国的加利福尼亚还产出了具有薄荷味儿和桉树味儿的葡萄。成大器指数：极高陈年指数：极高风情标识：黑醋栗，黑樱桃，青椒，时间还会让她呈现出皮革，烟熏，香草。身材：足够的酸度和单宁使她非常紧实，属于大骨架型的气场女王。口感：使用赤霞珠酿造的葡萄酒拥有中高酸的酒体和酒精度，以及中高-高单宁的特点。著名产区：美国加州纳帕谷、澳大利亚库纳瓦拉、意大利托斯卡尼、法国波尔多左岸。 梅洛（Merlot）和赤霞珠不同的是梅洛的酒精度比较高，所以酿制出来的葡萄酒都是属于柔美优雅的类型，梅洛酿制出来的酒一般饮用者女性用户数量要大于男性，一般年轻女性就爱喝梅洛葡萄酿制的酒。成大器指数：一般较低陈年指数：一般风情标识：黑醋栗，黑樱桃，青椒，香草身材：介于微胖和丰满之间，有肉感得刚刚好口感：使用梅洛酿出的葡萄酒通常酒体丰满、酒精度高，中等单宁酸度。著名产区：美国加州、意大利托斯卡尼、法国波尔多波美侯和圣艾米隆。 马尔贝克（）马尔贝克本来和梅洛一样，在波尔多混酿里担当提供酒体和果味的角色。但是1956年波尔多的一场特大霜冻，抗病性没有梅洛强的马尔贝克惨受打击，种植量大幅降低，地位最终被梅洛取代。 被波尔多扫地出门的马尔贝克，也在新世界国家——阿根廷闯出了一番天。 现在马尔贝克在阿根廷的产量占了整个世界产量的75%以上，成了名副其实的阿根廷“国酒”。 风味：在新家阿根廷旺盛生长的马尔贝克以“水果炸弹”著称。它有着特别突出的果味儿，尤其是李子味儿，可不是所有的品种都能够这么天然果味突出的。说它是葡萄品种果味最优秀的也不为过。口感：中等酸度、中等单宁、中等酒体，喝起来平易近人，毫无侵略性。适饮期：普通的、以果香为主导的马尔贝克应趁年轻尽早饮用，最多放个3-5年；顶级马尔贝克陈年潜力佳，瓶陈15年后方达巅峰状态。著名产地：阿根廷Mendoza、San Juan和Salta，其中Mendoza最广为人知，它的两个子产区Luján de Cuyo和Uco Valley质量最高。法国西南部Cahors。 歌海娜（）一种果粒很大一颗颗而表皮却很薄的葡萄，这种葡萄很甜，所含的糖分非常之高，它主要产自法国、西班牙等葡萄酒大国，这种葡萄吃起来和黑加仑一样很有口感，而且经常会伴有肉桂和烟草等香料的香味儿，歌海娜最有名的产区为南罗纳。 品丽珠（Cabernet Franc）金粉黛（Zinfandel）加州无疑是仙粉黛表现最出色的地区，其葡萄酒的产量和质量都首屈一指。风味：红色果实、果酱偏多；甜香料，野性草本；酒精度高，酒体更重。口感：丰腴,甜感明显的果味和香料涌满口腔,特别柔软易饮。但是她的层次感一般,容易腻人。适饮期：一般不能陈年。著名产地：王牌加州产区Dry Creek Valley是最有名的 Zinfandel 产区，从平衡型到高酒精型都有。精品产区Russian River Valley，气候凉爽，酸度偏高。 普通金粉黛 白金粉黛 味而多（Petit Verdot）在波尔多（Bordeaux），味而多是除了梅洛、赤霞珠和品丽珠以外最重要的红葡萄品种。味而多（Petit Verdot）源自法国西南部的吉伦特河（Gironde）流域，其名字中的“Verdot”由意表绿色的“Vert”演变而来，表明了其因晚熟的缘故，果皮在采摘时常常还带有青绿色的特性。风味：黑色水果、矿物质、甘草和黑胡椒。 未知佳美娜赛美蓉麝香品种间比较 喜凉喜热 喜凉的品种葡萄的酸度高糖分低，而且更容易出寒带水果味儿，所以酿出的酒果味更清新，更具酸度，更轻盈。 喜热的品种一般被种在气候温暖的地方，成熟条件好，所以通常会更重口味，成熟度高糖分高，果味更成熟甚至偏热带水果或果酱的风味。 喜凉 喜热 酸度高 成熟度高 糖分低 糖分高 果味清新 果味成熟 早熟晚熟 早熟成熟得比较早的品种更适宜被种植在冷凉产区，放缓他到达成熟的过程，这样方便发展出更为丰富和精致的风味。比如黑皮诺、霞多丽。 晚熟成熟得比较晚的品种更适宜种植在温暖甚至炎热的产区，因为他们本就难熟，需要额外多的热量和光照。比如赤霞珠、雷司令。 皮厚皮薄 皮厚的品种抗病性强，单宁、色素含量更多，如果落实到口味上就是涩度高，颜色深。 皮薄葡萄酿成的酒颜色通常略浅，而且更容易感染贵腐菌，有做贵腐酒的可能。 有桶无桶 适合过桶一般来说只有果味更成熟、更浓郁丰厚、结构更扎实、更有陈年潜力的品种才适合过桶。比如赤霞珠、西拉。香气类型为中性的白葡萄品种，说白了就是不香的品种，特别需要木桶来“粉饰”来增加复杂度，霞多丽就是最好的例子。 不适合过桶有些酒就为喝个新鲜劲儿，过了桶反而把果味儿给掩盖住了，比如佳美、灰皮诺。芳香型的白葡萄也不适合过桶，所谓芳香型，顾名思义就是特别芳香，这种芳香通常都不是果味本身，而是额外的花类植物类香料类的芳香，比如说雷司令和长相思，而这种香气和木桶型的香气是非常相冲突的，所以这样的酒往往会选择在不锈钢桶而不是橡木桶里发酵和陈放，当然也就不会有桶味儿啦。 干型甜型 糖酸比高甜、高酸是酿制甜型酒的重要的因素，有足够高的含糖量的同时，酸度可以起到很好的解腻作用，比如雷司令；而酸度不高的甜酒会让你腻的难以下咽，比如霞多丽。 皮薄厚皮儿薄的品种很容易感染贵腐菌做成贵腐甜酒，比如雷司令，当然霞多丽皮儿其实也薄，但在雷司令霞多丽这对对比中，主要就是酸度的差别。 香气芳香型葡萄品种可以为甜酒带来那种扑鼻而来的魅力。比如琼瑶浆、雷司令。 单品还是混酿 单品 平衡感高的葡萄品种，香气、颜色、单宁、酸度和酒体都足够高，什么也不缺，所以也就没有与其他品种混酿的必要啦。比如雷司令、黑皮诺。 适合混酿 梅洛、歌海娜这样的品种经常用于混酿，因为梅洛缺香气，歌海娜缺乏结构感。 赤霞珠的平衡感本来是很高的，但在波尔多这种边缘性气候中，往往造成酒体过轻，这个时候比赤霞珠容易成熟，酒体更为圆润扎实的梅洛就派上用场，用来补上酒体。 葡萄品种个性6个因素 葡萄品种风味5个因素 买酒（看酒标）通用 酒精度 酒精度偏低（11°、12°左右）意味着这款酒偏酸爽 酒精度偏高（14°左右）意味着这款酒相对浓郁、圆润 而极低或是极高酒精度（低于11°或者高于17°）一般意味着这款酒是甜型的 产地气候 旧世界冷的产地偏多，酸度高，浓郁度低 新世界热的产地普遍果味重，浓郁度高 年份 年轻的酒，过桶时间大多很短，果味简单。 年份越老的酒喝起来越顺滑、越有咸香、湿土、巧克力甚至菜味儿等陈年的感觉，会更复杂，但是并不一定所有人都会喜欢。 过桶与否 酒标年份是在距现在1年以内的酒：这种酒一般没有经过橡木桶培养，风格普遍以酸爽为主，或者以品种芳香为主，当然不排除向酒中加入橡木片来增加橡木风味的酒。 酒标年份是在距现在2到3年，尤其是3年以外，并且是在售卖架上最新出售的酒，这种酒一般是经过橡木桶培养的，我们称其走木桶路线。 生产商的性质 酒庄酒estate wines 这种酒的生产商一般指从葡萄园耕作、到酿酒、到陈年、到装瓶都由酒庄自己完成的小作坊，酒庄酒可以生产质量非常优质的酒，但也有品质很差劲的酒庄酒。 量产品牌generic brands 这种酒的生产商一般从各地买葡萄，是生产标准化产品的饮料公司。虽说量产品牌一般产不出精品酒，但也有很多量产品牌酒的性价比是相当不错的。 酒标德国酒http://jiu.ifeng.com/a/20160608/41620574_0.shtml 法国 AOC（或AOP，法定产区） AOC 的全称是 Appellation d’Origine Controllee，字面意思是“原产地控制命名”，指的是法定产区。也就是说，该酒确定来自于某个特定产区，采用特定的原材料，以特定的生产方式酿造的。 你可以看到酒标上会出现「Appellation 产地名 controlle」这样的格式。比如波尔多大区的酒就是「Appellation Bordeaux Controlle」。 在法国只有香槟和一些特别有名的子产区，它就不受这种格式的要求。比如香槟只写 Champagne，理论上他的完整版应该是 Appellation Champagne Controlle。 VDP（或IGP，地区餐酒） VDT（或Vin de France，日常餐酒） 意大利 产地评级（部分参考依据） DOCG（优质法定产区） DOC（法定产区） IGT（地区餐酒） VDT（日常餐酒） 酒标术语 Classico（古典）通常表示更为优质的子产区。 Superiore（优质）通常指风味更浓郁，酒精度更高的酒款。 Riserva（珍藏）通常指这类酒在发售前的窖藏时间更长。 ABBBC和PPM ABBBC是意大利最有代表性的五种大名酒 PPM代表了3种市场上更常见、价格也更亲民的意大利酒 风味（香气） 一级香气或者一级风味（Primary aroma or primary flavor）葡萄果实所带来的味道。 果味只要是葡萄酒，就有果味，因为葡萄就是水果。但如果只有果味的话，那就说明是一个很简单，没什么品头，而且通常体现不出来葡萄酒的品种特征和产地特征，只能体现出气候在酒里的影响。 芳香味花类（floral），植物类（vegetal/herbal），香料类（ spicy）虽然肉桂、玫瑰、和青椒之间差别很大，但它们都属于和植物有关的香气，给人的感觉多少是偏清新张扬的，而不是湿闷厚沉的。一般以这种香气先声夺人的都是芳香型葡萄品种，比如琼瑶浆，长相思等。就算不是芳香型的品种，一般来说，也会传达自己比较标志性的芳香型风味，比如黑皮诺里的玫瑰，西拉里的黑胡椒，成熟度有限的赤霞珠里的醋栗叶等等。可以说，芳香类风味很大程度上体现了葡萄品种的特征。 土石味葡萄酒里的矿石气息不是简单的葡萄藤吸取了矿物质所以产生的矿物质味，总的来说是个争议非常大的话题。 二级风味（secondary flavor）酿制过程中产生的味道。 木桶的影响木桶包括烤香、甜辛香等，比如香草，椰子粉，肉桂，丁香这些。 发酵的影响发酵后死掉的酵母 lees 的味道、苹果酸乳酸发酵留下的味道——它们会给酒带来奶油般的味道和质感，一般在白葡萄酒里更容易能够喝出来。 三级风味（tertiary flavor）陈年过程中产生的味道。到底都有哪些呢？相当复杂，一言难尽。我总结了5类，他们分别是：坚果类（nutty），焦糖类（caramel），动物/森林类（forest/gamey），熏烤类（smoky），香脂类（balsamic）。 焦糖类和熏烤类给人留下那种受过热作用的印象 坚果类和香脂类给人留下经受过氧化或干化的印象 动物森林类给人留下经受过微生物作用后的印象 总结 如果我们建立一个以复杂度为竖轴，浓郁度为横轴的坐标图，我们可以把繁杂的葡萄酒风味分成4个风格类型： 果味淡，但复杂度高的沉郁型：以高级勃艮第黑皮诺为典型代表， 果味淡，复杂度也低的清淡型：以任何市面上的100块以下的酒为典型代表， 果味浓，复杂度也高的丰富型：以高级波尔多赤霞珠混酿为典型代表， 果味浓，但复杂度低的奔放型：以澳洲西拉为典型代表。 饮用酒杯![image](/images/life/wine/3268.webp) 基本 进阶 酒塞木塞材质 人工合成木塞用这种塞的基本上是便宜酒。 碎木塞这种使用软木塞下角料压制出来的碎塞，效果比普通人工合成塞好点有限。而且由于用了粘结剂，和酒液长期直接接触也不太好。 贴片软木塞（或称1+1型木塞）这种碎木塞会在碎塞的两端贴软木片，一是会让人以为此塞非彼（碎）塞，二是避免碎木和黏合剂直接接触酒液。这种木塞，只能说比最普通的碎木塞好点有限。 DIAM压缩合成软木塞这种碎塞在制作过程中精选软木颗粒并进行真空二氧化碳去除可能产生木塞污染的三氯苯甲醚，消除了TCA污染的可能性。 填充塞这里是距离天然软木塞最近的一步啦！填充塞的基础本体使用的是等级较低的软木塞，但由于这种软木塞气孔大小不一、有些甚至相连，直接使用会有溢酒的可能，需要使用软木屑和黏合剂进行填充。从左至右分别为天然软木塞、填充塞和1+1型木塞 天然软木塞用完整的树皮制作的，而不是用碎片黏在一起的木塞。等级比较低的天然软木塞上面会坑坑洼洼充满疤痕，而特别高级的软木塞表面就会非常的光滑。 木塞品质 酒塞的长短 加长版木塞的隔离效果更好，会减少空气流通性，延长葡萄酒陈化过程。 酒塞上的印刷字样 最低级的就是上面什么也没有，或者印个葡萄图案的这种通用塞。这种都是非定制的，价钱也最便宜。 再往上走一个档次呢，就开始出现酒庄的名字了，有些还会把自己的网址给印上去。 高档的酒除了自己的名字，还有可能会印上年份。如果是非常顶级的老酒，酒庄还可能提供换塞服务。1942年的滴金酒庄的木塞，是在2010年酒庄换过塞的，这些信息已经都被标注在木塞上。 木塞常见情况 霉塞 原因：酒塞存储环境的湿度较高，给霉菌提供了完美的生长环境。 结论：不必担心，只要霉菌没染到木塞下端就好！ 解决办法：没污染到木塞下端的话，直接把塞口擦干净就好。 裂塞 原因： 如果是20年以上的老酒，木头会腐朽，所以会比较脆弱； 开瓶方法不当，导致塞裂； 储存条件太干燥。 结论： 如果不是老酒，有可能是存储条件太干，或者酒瓶直立摆放。 还有就是你的开瓶方法太粗暴。 涨塞 原因： 受热或剧烈晃动 工艺问题导致的二次发酵 结论： 不是好迹象，保存或运输一定有问题。 解决方法： 如果涨塞情况严重，请直接联系商家退货。 漏液 原因： 随涨塞一起产生的 木塞比较干，密封不够好 木塞质量问题 酒庄把酒灌得太满（比如勃艮第家的leroy） 老酒 结论： 对酒的影响大小比较难讲，还是以口感说话为好。 嘬塞（香槟塞，下部分缩小了） 原因： 酒陈放时间长了 过气了 结论： 对于老香槟来说很正常，只要不过松就好。 而普通的非年份香槟发生嘬塞，那这瓶酒很可能是过气了。 饮用温度 原理 高温凸显香气和滋味、酒精度、甜度、气泡。 低温凸显酸度、单宁、苦度。 6~10度（冷藏2 ~ 4小时）桃红酒、清爽的白葡萄酒、甜酒、气泡酒。 10~16度（冷藏2 ~ 4小时）质量差的重酒体红酒、果味为主清爽红酒、浓郁的白葡萄酒。 16~18度（冷藏2 ~ 4小时）波特酒、浓郁的红酒、复杂的红酒。 降温 冰块由于冰水混合物的降温速度是最快的，所以冰块制冷会比前几种快上许多，一般将冰块放进冰桶加适量的水，只需要15分钟左右就可以达到适饮温度了。 双温区酒柜将上半调成16度储存红葡萄酒。下半调成12度储存白葡萄酒。 恒温酒柜以统一调成12度。喝红葡萄酒时直接拿出来在室温稍作静置回温。 冰箱最好保证你的冰箱没有异味，不然有可能影响到酒风味。 解酒并不存在什么“解酒大法”！ 你所听说的那些有“奇效”的解酒方法，最终都只能缓解醉酒状态，而不是消除：比如通过进食来在胃壁形成保护膜，减缓酒精的吸收速度；通过补充液体来防止酒精造成的脱水等。甚至有一些方法还不靠谱！详情可以查看营养师为我们提供的表格了解： 缓解方法 防止脱水 减缓酒精吸收 形成保护膜 ==加重脱水== ==加重酒精吸收== 蜂蜜水/柠檬水 &radic; 牛奶/酸奶 &radic; 营养食物 &radic; &radic; 茶/咖啡 &radic; 碳酸饮料 &radic; 葡萄糖溶剂 &radic; 杂粮主食 &radic; 品酒 看酒的色泽需要斜举酒杯，用白色背景，来判断色泽深浅。问题：这杯酒的颜色是深还是浅？这杯酒的边缘色是宽还是窄？ 先闻一次，再晃杯多闻几次判断强烈度和香气类型。若晃杯前后香气差很多，则需要醒酒。问题：这杯酒的香气是强还是弱？陈年程度是深还是浅？ 用酒“漱口”让酒在口腔停留3-5秒，充分感受。问题：这杯酒风味复杂还是不复杂？质感好还是不好？ 感受回味计算回味在口腔里残留多少秒钟。问题：这杯酒的回味留下的是酸，是涩，是酒精味，还是挥之不去的风味呢？ 侍酒 点酒时向客人确认详细的酒名酒款 开酒的动作是优雅的 了解酒的不同状态，如果酒的状态不好会为客人及时更换 为客人建议最佳的醒酒时间，并询问客人的意见 让点酒的人来试酒，等到客人示意可以了再按照合适的顺序倒酒 倒酒的动作优雅，每次都会拿酒袋抹一下瓶口；量很精准，不会一个杯子倒的少一个杯子倒的多；在倒酒的时候没有存在感，不会让客人感觉到被服务了 新的酒配的是新的杯子，而不是倒在老杯子里；加酒杯的时候不是杂乱无章的，而是依次往左或右加的 品酒词 品酒词 说明 Fresh 清爽 风味既不浓郁又不复杂，只是还有些酸度。一般是低价酒的代言。 Fruity 果味 葡萄酒的主要材料是葡萄，紧着果味做文章，说明没有其他风味。 Aperitif 适合餐前饮用 配正餐的酒，才是好的酒。 Elegant 气质好 为了掩盖平庸的客套话。 Classic 经典 没有什么出众的，一般以上，但又算不上优质。 Early Drinking 适合早饮 陈不了年，但我们知道，越能陈年的酒越好。 酒体厚薄 红酒厚度是指红酒酒体在口腔内，口腔所感受到的红酒的整体重量感。通俗的理解，我们在喝水时和喝牛奶时的感觉不同。喝水的感觉轻，而喝牛奶的感觉要厚重一些。 轻度酒体：味道感受起来轻盈透明，和我们喝白开水时感受到的重量相似。 轻中度酒体：在品味时，会感受到许多不同的风味，如同我们在喝果汁时的口感，轻巧而平衡。 中度酒体：这种红酒在口腔内产生的重量感，如同我们自制的果汁重量，比前者略重。 中高度酒体：酒体在口腔内感觉丰富，具有相当的重量感，与牛奶在口腔里的感觉相似。 高度酒体：在口腔里有明显的厚重感，强烈浓郁，沉甸甸的，如同喝浓豆浆或者浓郁的蜂蜜水。 验酒（杂味） 杂味 说明 瓶塞味（Corked） 木塞被一种叫TCA的化学物质污染，产生一种湿纸板，发霉的陈腐的地下室的味道。 氧化变质味（Oxidized） 受到氧气的侵袭而产生的坚果味、在空气中放久了的苹果酸味等。 还原味（Reduced） 酿造过程中，因为闭氧或二氧化硫添加过多的原因，出现臭鸡蛋味、大蒜味、橡胶味等。还原味可通过醒酒缓解。 餐酒搭配 金句：红酒配红肉，白酒配白肉 “红红白白”这个理论之所以经久不衰，道理很简单，白的东西一般口味更轻，红的东西一般口味更重，颜色和口味的轻重是一脉相承的。那么轻口味配轻的，重口味配重的，大自然的道理就是这么朴素。 一般来说红葡萄酒酒体非常厚重，酸度较高，单宁较高。而红葡萄酒中的单宁和红葡萄酒富含大量的维生素C与红肉中纤维柔化、感觉肉质更加细嫩。感觉就非常的美味。 为什么红葡萄酒不能够与白肉同吃呢？红葡萄酒不建议与白肉同吃，比如海鲜、鱼类、虾类等等，因为白肉里面富含有大量的细菌，而红葡萄酒中里有非常丰富的维生素C，当细菌遇到大量维生素会产生非常难受的味道。 白葡萄酒中富含大量「酸」，即可增加口感的清爽活性，就海鲜、鱼类来讲，非常具去腥效果，就如同一般在烹饪鱼或海鲜时，会滴上柠檬汁一样。 搭配原则 食物口味的轻重最重要，其次是甜咸，而且如果你想最大程度上的享受餐酒搭配，一定要在快嚼完或者刚咽下的时候开始喝酒。 你喜欢什么酒永远比什么一定会更搭配要更重要。除非，你喜欢的酒和你想吃的这道菜完全不搭，甚至有很严重的冲突。 对于口味复杂的中餐来说，桃红的适用性是最强的，因为介于红和白之间嘛，怎么配都看着顺眼，喝着顺口。 干红配火锅 对于泼辣的食物，要配新世界干红，适得其所的火上浇油。 咸感突出的食物配酸感突出的酒 香槟配上鱼子酱，鱼子酱也不咸了，香槟也不酸了。 一般来说，浓郁度中等，酸度比较突出的酒会被称为food friendly，或者被定义为food wine。这种酒一般不会抢食物的风头，同时还有万能的酸度让他们给食物去解咸解腻。 干红 x 鱼 鱼姑娘，非得想找红酒大叔，他俩在一起，不光彼此惹得一身腥，还让红酒大叔泛着一股老不知羞的金属味儿. 葡萄酒 x 汤 双方都是水命，就特别容易泛冲。汤体质的食物的确是配酒时的老大难，遇到这种食物就绕道走吧。 开瓶后可存放时间（剩半瓶以上） 白葡萄酒2天。 红葡萄酒3-5天。 香槟3-4天。 甜酒5天。]]></content>
      <categories>
        <category>非原创</category>
        <category>生活</category>
        <category>酒</category>
      </categories>
      <tags>
        <tag>葡萄酒</tag>
        <tag>红酒</tag>
      </tags>
  </entry>
</search>
